{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we build the pipeline to perform the necessary feature transformations prior to model fitting. The necessary changes are listed below. \n",
    "\n",
    "* Removing observations where 'Minutes Played' == 0\n",
    "* Include 'Venue' as important feature\n",
    "* Include 'Minutes Played' as important feature\n",
    "* One-hot encode 'Position', and then further filter into 'Defenders', 'Midfielders' and 'Attackers'\n",
    "* Create 'Season' feature using 'kickoff_time', as this feature is necessary to calculate 'Designated Penalty Takers' \n",
    "* Use 'Penalties Attempted' to calculate 'Designated Penalty Takers' \n",
    "* Include 'Shots on Target' as important feature \n",
    "* Include 'npxG' as important feature\n",
    "* Include 'Penalty Area Touches' as important feature\n",
    "* Compute 'Rolling xG' which will replace 'npxG', then drop 'npxG'\n",
    "* Calculate 'Team Rolling xG Matchups' by first using team data to first calculate 'Team Rolling xG' and 'Team Rolling xGA'. We can then calculate 'Team Rolling xG Difference', which allows us to calculate 'Team Rolling xG Matchups'\n",
    "* Calculate 'Rolling Shots on Target' to replace 'Shots on Target', then drop 'Shots on Target'\n",
    "* Calculate 'Rolling Penalty Area Touches' to replace 'Penalty Area Touches', then drop 'Penalty Area Touches'\n",
    "\n",
    "This should leave the final dataframe with the following features - Venue, Designated Penalty Taker, Rolling Shots on Target, Rolling xG, Rolling Penalty Area Touches, Team Rolling xG Matchup, Defenders, Midfielders, Attackers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline, FunctionTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant dataframes from source\n",
    "att_train = pd.read_csv('att_explore_original.csv', index_col = 0)\n",
    "att_test = pd.read_csv('att_test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to select specific columns\n",
    "def select_columns(dataframe):\n",
    "    columns = ['Player ID', 'Team', 'Opponent', 'Venue', 'Minutes Played', 'Position', 'kickoff_time', 'Penalties Attempted', 'Shots on Target', 'npxG', \n",
    "               'Penalty Area Touches'] \n",
    "    return dataframe[columns].copy()\n",
    "\n",
    "#transformer to drop rows with empty 'Position'\n",
    "class DropEmptyPositions(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[X['Position'] != '0']\n",
    "\n",
    "#transformer for one-hot encoding and creating position categories\n",
    "class PositionEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        #one hot encode positions\n",
    "        positions_encode = X['Position'].str.get_dummies(sep=',')\n",
    "        \n",
    "        #create new position categories\n",
    "        positions_encode['Defender'] = positions_encode[['RB', 'LB', 'CB']].any(axis=1).astype(int)\n",
    "        positions_encode['Midfielder'] = positions_encode[['DM', 'CM', 'LM', 'RM', 'AM']].any(axis=1).astype(int)\n",
    "        positions_encode['Attacker'] = positions_encode[['LW', 'RW', 'FW']].any(axis=1).astype(int)\n",
    "        \n",
    "        # Drop original position columns\n",
    "        positions_encode = positions_encode.drop(columns=['RB', 'LB', 'CB', 'DM', 'CM', 'LM', 'RM', 'LW', 'RW', 'AM', 'FW', 'WB'], errors='ignore')\n",
    "        \n",
    "        X = X.drop('Position', axis = 1)\n",
    "        \n",
    "        return pd.concat([X.reset_index(drop=True), positions_encode.reset_index(drop=True)], axis=1)\n",
    "\n",
    "#transformer for determining the season\n",
    "class SeasonDeterminer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Convert 'kickoff_time' to datetime if not already done\n",
    "        X['kickoff_time'] = pd.to_datetime(X['kickoff_time'])\n",
    "        \n",
    "        # Function to determine the season\n",
    "        def determine_season(kickoff_time):\n",
    "            month = kickoff_time.month\n",
    "            year = kickoff_time.year\n",
    "            if month >= 8:  # August to December\n",
    "                return f'{year}-{year + 1}'  # Current year to next year\n",
    "            else:  # January to July\n",
    "                return f'{year - 1}-{year}'  # Previous year to current year\n",
    "        \n",
    "        # Apply the function to create the 'Season' column\n",
    "        X['Season'] = X['kickoff_time'].apply(determine_season)\n",
    "        return X\n",
    "    \n",
    "    \n",
    "#transformer for calculating 'Designated Penalty Taker'\n",
    "class DesigPenTaker(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        #group observations by player ID and penalties attempted \n",
    "        pen_group = X.groupby('Player ID', as_index = False)['Penalties Attempted'].sum()\n",
    "\n",
    "        #remove obs with 0 penalties attempted \n",
    "        pen_group = pen_group[pen_group['Penalties Attempted'] > 0 ]\n",
    "\n",
    "        #create new dataframe which has 'kickoff_time', 'Season', 'penalties attempted' and 'team in it \n",
    "        team_pens = X[['kickoff_time', 'Season', 'Penalties Attempted', 'Team']].copy()\n",
    "\n",
    "        #now we group by team and season to compute how many penalties were taken by each team in each season\n",
    "        team_pens_summary = team_pens.groupby(['Season', 'Team'], as_index=False)['Penalties Attempted'].sum()\n",
    "        team_pens_summary.rename(columns={'Penalties Attempted': 'Team Penalties'}, inplace=True)\n",
    "\n",
    "        #create empty dataframe\n",
    "        pen_prop = pd.DataFrame()\n",
    "\n",
    "        #loop through to get the Player ID and Penalties Attempted for each team in each season, filtering so that we only include observations with at \n",
    "        #least 1 penalty taken \n",
    "        for index, row in team_pens_summary.iterrows():\n",
    "            team = row['Team']\n",
    "            season = row['Season']\n",
    "    \n",
    "            filtered = X[(X['Season'] == season) & (X['Team'] == team) & (X['Penalties Attempted'] > 0)][['Player ID', 'Penalties Attempted']]\n",
    "            filtered['Team'] = team\n",
    "            filtered['Season'] = season\n",
    "            pen_prop = pd.concat([pen_prop, filtered], ignore_index= True)\n",
    "\n",
    "        #adding a new column into pen_prop called 'Team Penalties' which merges the relevant information from team_pens_summary\n",
    "        pen_prop = pen_prop.merge(team_pens_summary, on=['Team', 'Season'], how='left')\n",
    "\n",
    "        #we now merge rows that have the same player ID, team and season together. For the rows that satisfy this, we sum the penalties attempted to \n",
    "        #reflect the number of penalties a particular player ID took in a given season \n",
    "        merged_penprop = pen_prop.groupby(['Team', 'Season', 'Player ID'], as_index=False).agg({\n",
    "            'Penalties Attempted': 'sum',\n",
    "            'Team Penalties': 'first'  \n",
    "        })\n",
    "        merged_penprop = merged_penprop.sort_values(by='Player ID')\n",
    "\n",
    "        #adding new column called Proportion of Team Penalties Taken\n",
    "        merged_penprop['Proportion of Team Penalties Taken'] = (merged_penprop['Penalties Attempted'] / merged_penprop['Team Penalties'])\n",
    "\n",
    "        #final dataframe which merges the rows based on Player ID. Each row now corresponds to one unique player ID, the penalties attempted and team \n",
    "        #penalties columns are now summed. The proportion is then recalculated \n",
    "        penprop_summary = merged_penprop.groupby('Player ID').agg(\n",
    "            Penalties_Attempted=('Penalties Attempted', 'sum'),\n",
    "            Team_Penalties=('Team Penalties', 'sum')\n",
    "        ).reset_index()\n",
    "\n",
    "        penprop_summary['Proportion of Team Penalties Taken'] = (\n",
    "        penprop_summary['Penalties_Attempted'] / penprop_summary['Team_Penalties'])\n",
    "\n",
    "        #first off, we can probably include all player ID's with 100% team penalties taken as 'designated penalty takers'\n",
    "        desig_pen_takers = penprop_summary.loc[penprop_summary['Proportion of Team Penalties Taken'] == 1, 'Player ID'].tolist()\n",
    "\n",
    "        #we now add the Player ID's of players that took more than 50% of their team's penalties \n",
    "        additional_takers = penprop_summary.loc[penprop_summary['Proportion of Team Penalties Taken'] > 0.5, 'Player ID'].tolist()\n",
    "        desig_pen_takers.extend(additional_takers)\n",
    "\n",
    "        #construct 'Designated Penalty Taker' feature \n",
    "        X['Designated Penalty Taker'] = X['Player ID'].isin(desig_pen_takers).astype(int)\n",
    "        \n",
    "        #remove 'Penalties Attempted' column\n",
    "        X = X.drop('Penalties Attempted', axis = 1)\n",
    "    \n",
    "        return X\n",
    "\n",
    "\n",
    "#transformer for calculating 'Rolling xG'\n",
    "class RollingxG(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        #sort values by Player ID and kickoff_time, we also need to reset the index to ensure that the shifting in the function below works as intended\n",
    "        X.sort_values(by=['Player ID', 'kickoff_time'], inplace=True)\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        #function to calculate rolling xG\n",
    "        def calculate_rolling_xg(group):\n",
    "            # Calculate the cumulative sum and the number of games played\n",
    "            cumulative_sum = group['npxG'].cumsum()\n",
    "            count = pd.Series(range(1, len(group) + 1), index=group.index)\n",
    "    \n",
    "            # Create a new Series for rolling xG\n",
    "            rolling_xg = cumulative_sum.shift(1)/count.shift(1)\n",
    "    \n",
    "            return rolling_xg\n",
    "\n",
    "        #apply function\n",
    "        X['Rolling xG'] = X.groupby(['Player ID', 'Season']).apply(calculate_rolling_xg, include_groups = False).reset_index(drop = True)\n",
    "        \n",
    "        #drop 'npxG' column\n",
    "        X = X.drop('npxG', axis = 1)\n",
    "        \n",
    "        return X\n",
    "\n",
    "\n",
    "#transformer for calculating 'Rolling Team xG Matchup'\n",
    "class RollingxG_Matchup(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X):\n",
    "        #load in team data file \n",
    "        team_finaldat = pd.read_csv('team_finaldat.csv', index_col= 0)\n",
    "\n",
    "        #drop irrelevant columns\n",
    "        team_finaldat = team_finaldat.drop(columns = ['Referee', 'Attendance', 'Formation', 'Opposition Formation'])\n",
    "        \n",
    "        #we can see that the team data is first grouped by 'Team', but then 'Date' is backwards. Let's amend this. \n",
    "        team_finaldat = team_finaldat.sort_values(by=['Team', 'Date'], ascending=[True, True])\n",
    "        \n",
    "        #determine_season function, which converts kickoff_time into 'Season\n",
    "        def determine_season(kickoff_time):\n",
    "            month = kickoff_time.month\n",
    "            year = kickoff_time.year\n",
    "            if month >= 8:  # August to December\n",
    "                return f'{year}-{year + 1}'  # Current year to next year\n",
    "            else:  # January to July\n",
    "                return f'{year - 1}-{year}'  # Previous year to current year\n",
    "        \n",
    "        \n",
    "        #we now want to add in rolling xG and xGA for teams. We can try reuse the functions used previously, to do this we need to add the 'Season' feature \n",
    "        # to the team_finaldat dataframe\n",
    "        team_finaldat['Date'] = pd.to_datetime(team_finaldat['Date'])\n",
    "        team_finaldat['Season'] = team_finaldat['Date'].apply(determine_season)\n",
    "\n",
    "        #sort values by Team and Date, we also need to reset the index to ensure that the shifting in the function below works as intended\n",
    "        team_finaldat.sort_values(by=['Team', 'Date'], inplace=True)\n",
    "        team_finaldat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        #function to calculate rolling xG\n",
    "        def calculate_rolling_teamxg(group):\n",
    "            # Calculate the cumulative sum and the number of games played\n",
    "            cumulative_sum = group['xG'].cumsum()\n",
    "            count = pd.Series(range(1, len(group) + 1), index=group.index)\n",
    "    \n",
    "            # Create a new Series for rolling xG\n",
    "            rolling_xg = cumulative_sum.shift(1)/count.shift(1)\n",
    "    \n",
    "            return rolling_xg\n",
    "\n",
    "        #function to calculate rolling xGA\n",
    "        def calculate_rolling_teamxga(group):\n",
    "            # Calculate the cumulative sum and the number of games played\n",
    "            cumulative_sum = group['xGA'].cumsum()\n",
    "            count = pd.Series(range(1, len(group) + 1), index=group.index)\n",
    "    \n",
    "            # Create a new Series for rolling xG\n",
    "            rolling_xg = cumulative_sum.shift(1)/count.shift(1)\n",
    "    \n",
    "            return rolling_xg\n",
    "\n",
    "        #apply function to get rolling xG and xGA for each team \n",
    "        team_finaldat['Team Rolling xG'] = team_finaldat.groupby(['Team', 'Season']).apply(calculate_rolling_teamxg, include_groups = False).reset_index(drop = True)\n",
    "        team_finaldat['Team Rolling xGA'] = team_finaldat.groupby(['Team', 'Season']).apply(calculate_rolling_teamxga, include_groups = False).reset_index(drop = True)\n",
    "        \n",
    "        #create xg/xga diff feature \n",
    "        team_finaldat['Team xG Difference'] = team_finaldat['xG'] - team_finaldat['xGA']\n",
    "        \n",
    "        #function to calculate rolling xg diff\n",
    "        def calculate_rolling_teamxgdiff(group):\n",
    "            # Calculate the cumulative sum and the number of games played\n",
    "            cumulative_sum = group['Team xG Difference'].cumsum()\n",
    "            count = pd.Series(range(1, len(group) + 1), index=group.index)\n",
    "    \n",
    "            # Create a new Series for rolling xG\n",
    "            rolling_xg = cumulative_sum.shift(1)/count.shift(1)\n",
    "    \n",
    "            return rolling_xg\n",
    "\n",
    "        team_finaldat['Team Rolling xG Difference'] = team_finaldat.groupby(['Team', 'Season']).apply(calculate_rolling_teamxgdiff, include_groups = False).reset_index(drop = True)\n",
    "        \n",
    "        #merge original dataframe with team data\n",
    "        merged_df = X.merge(\n",
    "            team_finaldat[['Season', 'Venue', 'Team', 'Opponent', 'Team Rolling xG', 'Team Rolling xGA', 'Team Rolling xG Difference']],\n",
    "            on=['Season', 'Venue', 'Team', 'Opponent'],\n",
    "            how='left'  \n",
    "        )\n",
    "\n",
    "        X['Team Rolling xG'] = merged_df['Team Rolling xG']\n",
    "        X['Team Rolling xGA'] = merged_df['Team Rolling xGA']\n",
    "        X['Team Rolling xG Difference'] = merged_df['Team Rolling xG Difference']\n",
    "        \n",
    "        #now, calculate rolling xG team matchups\n",
    "        #create the new feature, lets call it 'Team Rolling xG Matchups' \n",
    "        X['Team Rolling xG Matchup'] = None\n",
    "\n",
    "        #group by 'Team', 'Opponent', 'Season', and 'Venue'\n",
    "        for (team, opponent, season, venue), group in X.groupby(['Team', 'Opponent', 'Season', 'Venue']):\n",
    "            #initialize none values\n",
    "            team_xgdiff = None\n",
    "            opp_xgdiff = None\n",
    "\n",
    "            #get team xg diff\n",
    "            if group['Team Rolling xG Difference'].nunique() == 1:\n",
    "                team_xgdiff = group['Team Rolling xG Difference'].iloc[0]\n",
    "\n",
    "            #get opponent rows\n",
    "            opponent_row = X[\n",
    "                (X['Team'] == opponent) &\n",
    "                (X['Opponent'] == team) &\n",
    "                (X['Season'] == season) &\n",
    "                (X['Venue'] != venue)  # Ensure venue is opposite\n",
    "            ].reset_index(drop=True)\n",
    "\n",
    "            #make sure opponent rows have the same team rolling xG diff, if so select any\n",
    "            if opponent_row['Team Rolling xG Difference'].nunique() == 1:\n",
    "                opp_xgdiff = opponent_row['Team Rolling xG Difference'].iloc[0]\n",
    "            #calculate xg matchup val\n",
    "            if team_xgdiff is not None and opp_xgdiff is not None:\n",
    "                xg_matchup = team_xgdiff - opp_xgdiff\n",
    "            else:\n",
    "                xg_matchup = None  # handle cases where values are not available\n",
    "\n",
    "            #assign the calculated value back to the original DataFrame\n",
    "            X.loc[group.index, 'Team Rolling xG Matchup'] = xg_matchup\n",
    "        \n",
    "        #drop the unnecessary columns\n",
    "        X = X.drop(['Team Rolling xGA', 'Team Rolling xG Difference'], axis = 1)\n",
    "            \n",
    "        return X\n",
    "    \n",
    "    \n",
    "#transformer for calculating 'Rolling Shots on Target'\n",
    "class RollingSOT(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        #sort values by Player ID and kickoff_time, we also need to reset the index to ensure that the shifting in the function below works as intended\n",
    "        X.sort_values(by=['Player ID', 'kickoff_time'], inplace=True)\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        #function to calculate rolling SOT\n",
    "        def calculate_rolling_sot(group):\n",
    "            # Calculate the cumulative sum and the number of games played\n",
    "            cumulative_sum = group['Shots on Target'].cumsum()\n",
    "            count = pd.Series(range(1, len(group) + 1), index=group.index)\n",
    "    \n",
    "            # Create a new Series for rolling xG\n",
    "            rolling_sot = cumulative_sum.shift(1)/count.shift(1)\n",
    "    \n",
    "            return rolling_sot\n",
    "\n",
    "        #apply function\n",
    "        X['Rolling Shots on Target'] = X.groupby(['Player ID', 'Season']).apply(calculate_rolling_sot, include_groups = False).reset_index(drop = True)\n",
    "        \n",
    "        #drop 'Shots on Target' column\n",
    "        X = X.drop('Shots on Target', axis = 1)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "#transformer for calculating 'Rolling Penalty Area Touches'\n",
    "class RollingPAT(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        #sort values by Player ID and kickoff_time, we also need to reset the index to ensure that the shifting in the function below works as intended\n",
    "        X.sort_values(by=['Player ID', 'kickoff_time'], inplace=True)\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        #function to calculate rolling SOT\n",
    "        def calculate_rolling_pat(group):\n",
    "            # Calculate the cumulative sum and the number of games played\n",
    "            cumulative_sum = group['Penalty Area Touches'].cumsum()\n",
    "            count = pd.Series(range(1, len(group) + 1), index=group.index)\n",
    "    \n",
    "            # Create a new Series for rolling xG\n",
    "            rolling_pat = cumulative_sum.shift(1)/count.shift(1)\n",
    "    \n",
    "            return rolling_pat\n",
    "\n",
    "        #apply function\n",
    "        X['Rolling Penalty Area Touches'] = X.groupby(['Player ID', 'Season']).apply(calculate_rolling_pat, include_groups = False).reset_index(drop = True)\n",
    "        \n",
    "        #drop 'Penalty Area Touches' column\n",
    "        X = X.drop('Penalty Area Touches', axis = 1)\n",
    "        \n",
    "        return X\n",
    "\n",
    "\n",
    "#transformer that drops the columns in the dataframe that we needed for feature transformation, but we don't need for model fitting\n",
    "class DropFinal(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        X = X.drop(['Player ID', 'Team', 'Opponent', 'kickoff_time', 'Season'], axis = 1)\n",
    "        return X\n",
    "\n",
    "#FunctionTransformer to select the necessary columns\n",
    "select_transformer = FunctionTransformer(select_columns)\n",
    "\n",
    "# Create a Pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    ('select', select_transformer), \n",
    "    ('drop_empty_pos', DropEmptyPositions()), \n",
    "    ('encode_positions', PositionEncoder()), \n",
    "    ('determine_season', SeasonDeterminer()), \n",
    "    ('desig_pen_taker', DesigPenTaker()), \n",
    "    ('rolling_xg', RollingxG()), \n",
    "    ('rolling_sot', RollingSOT()),\n",
    "    ('rolling_pat', RollingPAT()),\n",
    "    ('rolling_xg_matchup', RollingxG_Matchup()), \n",
    "    ('drop_final', DropFinal())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pipeline to transform the DataFrame\n",
    "att_train_processed = pipe.fit_transform(att_train)\n",
    "att_test_processed = pipe.fit_transform(att_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
