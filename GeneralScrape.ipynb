{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd \n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_url_final function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function just gets the html code that we need to scrape for data, updated version that is not specific to salah \n",
    "def get_url_final(code, year_range, category, player):\n",
    "    base_url = 'https://fbref.com/en/players/{}/matchlogs/{}/c9/{}/{}-Match-Logs'\n",
    "    url = base_url.format(code, year_range, category, player)\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    html_filtered = soup.find('tbody')\n",
    "    return(html_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_dat, get_date and get_matchweek functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dat(dat, col):\n",
    "    coldat = []\n",
    "    for row in dat.find_all('tr'):\n",
    "        if not row.attrs:\n",
    "            coldat.append(row.find('td', {'data-stat': col}).text)\n",
    "    return (coldat)   \n",
    "\n",
    "def get_date(dat, col):\n",
    "    coldat = []\n",
    "    for row in dat.find_all('tr'):\n",
    "        if not row.attrs:\n",
    "            coldat.append(row.find('th', {'data-stat': col}).text)\n",
    "    return (coldat)   \n",
    "\n",
    "def get_matchweek(dat, col):\n",
    "    coldat = []\n",
    "    for row in dat.find_all('tr'):\n",
    "        if not row.attrs:\n",
    "            coldat.append(row.find('td', {'data-stat': col}).text)\n",
    "    coldat = [coldat.replace('Matchweek ', '') for coldat in coldat]\n",
    "    return(coldat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, we want to modify the function above, to allow us to get any players data that we want, not just salah\n",
    "\n",
    "def get_data(code, year_range, player, fpl_name):\n",
    "    data_summary = get_url_final(code, year_range, '', player)\n",
    "    \n",
    "    #this if statement is checking whether or not this player actually has data for the particular year. In the case that they do not actually have\n",
    "    #data for this year, just return an empty dataframe \n",
    "    if not data_summary:\n",
    "        empty = pd.DataFrame()\n",
    "        return(empty)\n",
    "    \n",
    "    data_passing = get_url_final(code, year_range, 'passing', player)\n",
    "    data_passingtype = get_url_final(code, year_range, 'passing_types', player)\n",
    "    data_gca = get_url_final(code, year_range, 'gca', player)\n",
    "    data_defense = get_url_final(code, year_range, 'defense', player)\n",
    "    data_possession = get_url_final(code, year_range, 'possession', player)\n",
    "    \n",
    "    ################################################################\n",
    "    #getting the data for the necessary columns\n",
    "    \n",
    "    ##### summary data #####\n",
    "    #misc data \n",
    "    date = get_date(data_summary, 'date')\n",
    "    day = get_dat(data_summary,'dayofweek')\n",
    "    matchweek = get_matchweek(data_summary, 'round')\n",
    "    venue = get_dat(data_summary, 'venue')\n",
    "    result = get_dat(data_summary, 'result')\n",
    "    team = get_dat(data_summary, 'team')\n",
    "    opponent = get_dat(data_summary, 'opponent')\n",
    "    start = get_dat(data_summary, 'game_started')\n",
    "    position = get_dat(data_summary, 'position')\n",
    "    mins = get_dat(data_summary, 'minutes')\n",
    "\n",
    "    #performance data\n",
    "    goals = get_dat(data_summary, 'goals')\n",
    "    assist = get_dat(data_summary, 'assists')\n",
    "    pen_goals = get_dat(data_summary, 'pens_made')\n",
    "    pen_attempted = get_dat(data_summary, 'pens_att')\n",
    "    shots = get_dat(data_summary, 'shots')\n",
    "    sot = get_dat(data_summary, 'shots_on_target')\n",
    "    yellow = get_dat(data_summary, 'cards_yellow')\n",
    "    red = get_dat(data_summary, 'cards_red')\n",
    "    touches = get_dat(data_summary, 'touches')\n",
    "    tackles = get_dat(data_summary, 'tackles')\n",
    "    interceptions = get_dat(data_summary, 'interceptions')\n",
    "    blocks = get_dat(data_summary, 'blocks')\n",
    "\n",
    "    #expected performance metrics\n",
    "    xg = get_dat(data_summary, 'xg')\n",
    "    npxg = get_dat(data_summary, 'npxg')\n",
    "    xag = get_dat(data_summary, 'xg_assist')\n",
    "\n",
    "    #shot creating actions\n",
    "    sca = get_dat(data_summary, 'sca')\n",
    "    gca = get_dat(data_summary, 'gca')\n",
    "\n",
    "    #passes\n",
    "    passes_completed = get_dat(data_summary, 'passes_completed')\n",
    "    passes_attempted = get_dat(data_summary, 'passes')\n",
    "    prg_passes = get_dat(data_summary, 'progressive_passes')\n",
    "\n",
    "    #carries \n",
    "    carries = get_dat(data_summary, 'carries')\n",
    "    prg_carries = get_dat(data_summary, 'progressive_carries')\n",
    "\n",
    "    #take-ons\n",
    "    takeon_att = get_dat(data_summary, 'take_ons')\n",
    "    takeon_suc = get_dat(data_summary, 'take_ons_won')\n",
    "    \n",
    "    ##### passing data #####\n",
    "    #total\n",
    "    pass_distance = get_dat(data_passing, 'passes_total_distance')\n",
    "    prg_pass_distance = get_dat(data_passing, 'passes_progressive_distance')\n",
    "\n",
    "    #short\n",
    "    short_pass_completed = get_dat(data_passing, 'passes_completed_short')\n",
    "    short_pass_attempted = get_dat(data_passing, 'passes_short')\n",
    "\n",
    "    #medium \n",
    "    med_pass_completed = get_dat(data_passing, 'passes_completed_medium')\n",
    "    med_pass_attempted = get_dat(data_passing, 'passes_medium')\n",
    "\n",
    "    #long\n",
    "    long_pass_completed = get_dat(data_passing, 'passes_completed_long')\n",
    "    long_pass_attempted = get_dat(data_passing, 'passes_long')\n",
    "\n",
    "    #misc\n",
    "    xa = get_dat(data_passing, 'pass_xa')\n",
    "    keypass = get_dat(data_passing, 'assisted_shots')\n",
    "    finalthird_pass = get_dat(data_passing, 'passes_into_final_third')\n",
    "    penaltyarea_pass = get_dat(data_passing, 'passes_into_penalty_area')\n",
    "    penaltyarea_cross = get_dat(data_passing, 'crosses_into_penalty_area')\n",
    "    \n",
    "    \n",
    "    ##### passing types data #####\n",
    "    live_pass = get_dat(data_passingtype, 'passes_live')\n",
    "    dead_pass = get_dat(data_passingtype, 'passes_dead')\n",
    "    freekick_pass = get_dat(data_passingtype, 'passes_free_kicks')\n",
    "    through_balls = get_dat(data_passingtype, 'through_balls')\n",
    "    switches = get_dat(data_passingtype, 'passes_switches')\n",
    "    crosses = get_dat(data_passingtype, 'crosses')\n",
    "    throwin = get_dat(data_passingtype, 'throw_ins')\n",
    "    corners = get_dat(data_passingtype, 'corner_kicks')\n",
    "    offside_pass = get_dat(data_passingtype, 'passes_offsides')\n",
    "    \n",
    "    \n",
    "    ##### gca data #####\n",
    "    #sca types \n",
    "    live_sca = get_dat(data_gca, 'sca_passes_live')\n",
    "    deadball_sca = get_dat(data_gca, 'sca_passes_dead')\n",
    "    takeons_sca = get_dat(data_gca, 'sca_take_ons')\n",
    "    shots_sca = get_dat(data_gca, 'sca_shots')\n",
    "    fouls_sca = get_dat(data_gca, 'sca_fouled')\n",
    "    defense_sca = get_dat(data_gca, 'sca_defense')\n",
    "\n",
    "    #gca types \n",
    "    live_gca = get_dat(data_gca, 'gca_passes_live')\n",
    "    deadball_gca = get_dat(data_gca, 'gca_passes_dead')\n",
    "    takeons_gca = get_dat(data_gca, 'gca_take_ons')\n",
    "    shots_gca = get_dat(data_gca, 'gca_shots')\n",
    "    fouls_gca = get_dat(data_gca, 'gca_fouled')\n",
    "    defense_gca = get_dat(data_gca, 'gca_defense')\n",
    "    \n",
    "    \n",
    "    ##### defensive data ######\n",
    "    #tackles\n",
    "    tackles_won = get_dat(data_defense,'tackles_won')\n",
    "    tackles_def = get_dat(data_defense, 'tackles_def_3rd')\n",
    "    tackles_mid = get_dat(data_defense, 'tackles_mid_3rd')\n",
    "    tackles_att = get_dat(data_defense, 'tackles_att_3rd')\n",
    "\n",
    "    #challenges \n",
    "    dribblers_tackled = get_dat(data_defense, 'challenge_tackles')\n",
    "    dribbles_challenged = get_dat(data_defense, 'challenges')\n",
    "    challenges_lost = get_dat(data_defense, 'challenges_lost')\n",
    "\n",
    "    #blocks \n",
    "    shots_blocked = get_dat(data_defense, 'blocked_shots')\n",
    "    pass_blocked = get_dat(data_defense, 'blocked_passes')\n",
    "    clearances = get_dat(data_defense, 'clearances')\n",
    "    def_errors = get_dat(data_defense, 'errors')\n",
    "    \n",
    "    \n",
    "    ##### possession data #####\n",
    "    #touches \n",
    "    def_penarea_touches = get_dat(data_possession, 'touches_def_pen_area')\n",
    "    def_third_touches = get_dat(data_possession, 'touches_def_3rd')\n",
    "    mid_third_touches = get_dat(data_possession, 'touches_mid_3rd')\n",
    "    att_third_touches = get_dat(data_possession, 'touches_att_3rd')\n",
    "    pen_area_touches = get_dat(data_possession, 'touches_att_pen_area')\n",
    "\n",
    "    #carries\n",
    "    carry_distance = get_dat(data_possession, 'carries_distance')\n",
    "    prg_carry_distance = get_dat(data_possession, 'carries_progressive_distance')\n",
    "    final_third_carries = get_dat(data_possession, 'carries_into_final_third')\n",
    "    pen_area_carries = get_dat(data_possession, 'carries_into_penalty_area')\n",
    "    miscontrols = get_dat(data_possession, 'miscontrols')\n",
    "    dispossesed = get_dat(data_possession, 'dispossessed')\n",
    "\n",
    "    #receiving \n",
    "    pass_received = get_dat(data_possession, 'passes_received')\n",
    "    prg_pass_received = get_dat(data_possession, 'progressive_passes_received')\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    #creating dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'Date': date,\n",
    "        'Day': day,\n",
    "        'Matchweek': matchweek,\n",
    "        'Venue': venue,\n",
    "        'Result': result,\n",
    "        'Team': team,\n",
    "        'Opponent': opponent, \n",
    "        'Start': start, \n",
    "        'Position': position,\n",
    "        'Minutes Played': mins, \n",
    "        'Goals': goals, \n",
    "        'Assists': assist, \n",
    "        'Penalties Scored': pen_goals, \n",
    "        'Penalties Attempted': pen_attempted, \n",
    "        'Shots': shots, \n",
    "        'Shots on Target': sot, \n",
    "        'Yellow Cards': yellow, \n",
    "        'Red Cards': red, \n",
    "        'Touches': touches, \n",
    "        'Tackles': tackles,\n",
    "        'Interceptions': interceptions, \n",
    "        'Blocks': blocks, \n",
    "        'xG': xg,\n",
    "        'npxG': npxg,\n",
    "        'xAG': xag, \n",
    "        'Shot Creating Actions': sca, \n",
    "        'Goal Creating Actions': gca, \n",
    "        'Passes Completed': passes_completed, \n",
    "        'Passes Attempted': passes_attempted, \n",
    "        'Progressive Passes': prg_passes,\n",
    "        'Carries': carries, \n",
    "        'Progressive Carries': prg_carries, \n",
    "        'Take-ons Attempted': takeon_att, \n",
    "        'Successful Take-ons': takeon_suc,\n",
    "        \n",
    "        'Passing Distance': pass_distance, \n",
    "        'Progressive Passing Distance': prg_pass_distance,\n",
    "        'Short Passes Completed' : short_pass_completed,\n",
    "        'Short Passes Attempted': short_pass_attempted,\n",
    "        'Medium Passes Completed': med_pass_completed,\n",
    "        'Medium Passes Attempted': med_pass_attempted,\n",
    "        'Long Passes Completed': long_pass_completed,\n",
    "        'Long Passes Attempted': long_pass_attempted,\n",
    "        'Expected Assists': xa,\n",
    "        'Key Passes': keypass,\n",
    "        'Passes into Final Third': finalthird_pass,\n",
    "        'Passes into Penalty Area': penaltyarea_pass,\n",
    "        'Crosses into Penalty Area': penaltyarea_cross,\n",
    "    \n",
    "        'Live Pass': live_pass,\n",
    "        'Dead Pass': dead_pass,\n",
    "        'Free Kick Pass': freekick_pass,\n",
    "        'Through Balls': through_balls,\n",
    "        'Switches': switches,\n",
    "        'Crosses': crosses,\n",
    "        'Throw Ins Taken': throwin,\n",
    "        'Corners Taken': corners,\n",
    "        'Passes Offside': offside_pass,\n",
    "    \n",
    "        'Live SCA': live_sca,\n",
    "        'Deadball SCA': deadball_sca,\n",
    "        'Take-on SCA': takeons_sca,\n",
    "        'Shot SCA': shots_sca,\n",
    "        'Foul SCA': fouls_sca,\n",
    "        'Defense SCA': defense_sca,\n",
    "    \n",
    "        'Live GCA': live_gca,\n",
    "        'Deadball GCA': deadball_gca,\n",
    "        'Take-on GCA': takeons_gca,\n",
    "        'Shot GCA': shots_gca,\n",
    "        'Foul GCA': fouls_gca,\n",
    "        'Defense GCA': defense_gca,\n",
    "    \n",
    "        'Tackles Won': tackles_won,\n",
    "        'Defensive Third Tackles': tackles_def,\n",
    "        'Middle Third Tackles': tackles_mid,\n",
    "        'Attacking Third Tackles': tackles_att,\n",
    "        'Dribblers Tackled': dribblers_tackled,\n",
    "        'Dribblers Tackled Attempts': dribbles_challenged,\n",
    "        'Challenges Lost': challenges_lost,\n",
    "        'Shots Blocked': shots_blocked,\n",
    "        'Passes Blocked': pass_blocked,\n",
    "        'Clearances': clearances,\n",
    "        'Defensive Errors': def_errors,\n",
    "    \n",
    "        'Defensive Penalty Area Touches': def_penarea_touches,\n",
    "        'Defensive Third Touches': def_third_touches,\n",
    "        'Middle Third Touches': mid_third_touches,\n",
    "        'Attacking Third Touches': att_third_touches,\n",
    "        'Penalty Area Touches': pen_area_touches,\n",
    "        'Carry Distance': carry_distance,\n",
    "        'Progressive Carry Distance': prg_carry_distance,\n",
    "        'Final Third Carries': final_third_carries,\n",
    "        'Carries into Penalty Area': pen_area_carries,\n",
    "        'Miscontrols': miscontrols,\n",
    "        'Dispossessed': dispossesed,\n",
    "        'Passes Received': pass_received,\n",
    "        'Progressive Passes Received': prg_pass_received\n",
    "    })\n",
    "    \n",
    "    #modifying data types\n",
    "    df = df.astype({\n",
    "        'Date': 'datetime64[ns]',\n",
    "        'Day': 'object',\n",
    "        'Matchweek': 'int64',\n",
    "        'Venue': 'object',\n",
    "        'Result': 'object',\n",
    "        'Team': 'object',\n",
    "        'Opponent': 'object', \n",
    "        'Start': 'object', \n",
    "        'Position': 'object',\n",
    "        'Minutes Played': 'int64', \n",
    "        'Goals': 'int64', \n",
    "        'Assists': 'int64', \n",
    "        'Penalties Scored': 'int64', \n",
    "        'Penalties Attempted': 'int64', \n",
    "        'Shots': 'int64', \n",
    "        'Shots on Target': 'int64', \n",
    "        'Yellow Cards': 'int64', \n",
    "        'Red Cards': 'int64', \n",
    "        'Touches': 'int64', \n",
    "        'Tackles': 'int64',\n",
    "        'Interceptions': 'int64', \n",
    "        'Blocks': 'int64', \n",
    "        'xG': 'float64',\n",
    "        'npxG': 'float64',\n",
    "        'xAG': 'float64', \n",
    "        'Shot Creating Actions': 'int64', \n",
    "        'Goal Creating Actions': 'int64', \n",
    "        'Passes Completed': 'int64', \n",
    "        'Passes Attempted': 'int64', \n",
    "        'Progressive Passes': 'int64',\n",
    "        'Carries': 'int64', \n",
    "        'Progressive Carries': 'int64', \n",
    "        'Take-ons Attempted': 'int64', \n",
    "        'Successful Take-ons': 'int64',\n",
    "        \n",
    "        'Short Passes Completed' : 'int64',\n",
    "        'Short Passes Attempted': 'int64',\n",
    "        'Medium Passes Completed': 'int64',\n",
    "        'Medium Passes Attempted': 'int64',\n",
    "        'Long Passes Completed': 'int64',\n",
    "        'Long Passes Attempted': 'int64',\n",
    "        'Expected Assists': 'float64',\n",
    "        'Key Passes': 'int64',\n",
    "        'Passes into Final Third': 'int64',\n",
    "        'Passes into Penalty Area': 'int64',\n",
    "        'Crosses into Penalty Area': 'int64',\n",
    "    \n",
    "        'Live Pass': 'int64',\n",
    "        'Dead Pass': 'int64',\n",
    "        'Free Kick Pass': 'int64',\n",
    "        'Through Balls': 'int64',\n",
    "        'Switches': 'int64',\n",
    "        'Crosses': 'int64',\n",
    "        'Throw Ins Taken': 'int64',\n",
    "        'Corners Taken': 'int64',\n",
    "        'Passes Offside': 'int64',\n",
    "    \n",
    "        'Live SCA': 'int64',\n",
    "        'Deadball SCA': 'int64',\n",
    "        'Take-on SCA': 'int64',\n",
    "        'Shot SCA': 'int64',\n",
    "        'Foul SCA': 'int64',\n",
    "        'Defense SCA': 'int64',\n",
    "    \n",
    "        'Live GCA': 'int64',\n",
    "        'Deadball GCA': 'int64',\n",
    "        'Take-on GCA': 'int64',\n",
    "        'Shot GCA': 'int64',\n",
    "        'Foul GCA': 'int64',\n",
    "        'Defense GCA': 'int64',\n",
    "    \n",
    "        'Tackles Won': 'int64',\n",
    "        'Defensive Third Tackles': 'int64',\n",
    "        'Middle Third Tackles': 'int64',\n",
    "        'Attacking Third Tackles': 'int64',\n",
    "        'Dribblers Tackled': 'int64',\n",
    "        'Dribblers Tackled Attempts': 'int64',\n",
    "        'Challenges Lost': 'int64',\n",
    "        'Shots Blocked': 'int64',\n",
    "        'Passes Blocked': 'int64',\n",
    "        'Clearances': 'int64',\n",
    "        'Defensive Errors': 'int64',\n",
    "    \n",
    "        'Defensive Penalty Area Touches': 'int64',\n",
    "        'Defensive Third Touches': 'int64',\n",
    "        'Middle Third Touches': 'int64',\n",
    "        'Attacking Third Touches': 'int64',\n",
    "        'Penalty Area Touches': 'int64',\n",
    "        'Carry Distance': 'float64',\n",
    "        'Progressive Carry Distance': 'float64',\n",
    "        'Final Third Carries': 'int64',\n",
    "        'Carries into Penalty Area': 'int64',\n",
    "        'Miscontrols': 'int64',\n",
    "        'Dispossessed': 'int64',\n",
    "        'Passes Received': 'int64',\n",
    "        'Progressive Passes Received': 'int64'\n",
    "    })\n",
    "    \n",
    "    #changing date column data type \n",
    "    df['Date'] = df['Date'].dt.date\n",
    "    \n",
    "    ###############################################################################\n",
    "    \n",
    "    #now we want to get the fpl data \n",
    "    start_year = year_range[:4] #getting the whole of the first year \n",
    "    end_year = year_range[-2:]\n",
    "    format_year = f'{start_year}-{end_year}'\n",
    "    directory = f'Fantasy-Premier-League/data/{format_year}/players'\n",
    "    files = os.listdir(directory)\n",
    "    csv_file = [f for f in files if fpl_name in f]\n",
    "    fpldf = pd.read_csv(os.path.join(directory, csv_file[0]) + '/gw.csv')\n",
    "\n",
    "    #some of the columns are duplicated (from the webscraped data), so we want to remove these \n",
    "    fpldf = fpldf.drop(['assists', 'expected_assists', 'expected_goal_involvements', 'expected_goals', 'fixture',\n",
    "                                          'goals_conceded', 'goals_scored', 'penalties_missed', 'penalties_saved', 'red_cards'\n",
    "                                          ,'team_a_score', 'team_h_score', 'was_home', 'yellow_cards', 'element', 'opponent_team', 'starts'\n",
    "                                          ,'expected_goals_conceded'], axis=1, \n",
    "                       errors = 'ignore')\n",
    "\n",
    "    #we now want to change the 'kickoff time' feature into a datetime object \n",
    "    fpldf['kickoff_time'] = pd.to_datetime(fpldf['kickoff_time'])\n",
    "\n",
    "    #creating new column, which is just the kickoff date \n",
    "    fpldf['kickoff_date'] = fpldf['kickoff_time'].dt.date\n",
    "    \n",
    "    finaldf = pd.merge(df, fpldf, left_on='Date', right_on='kickoff_date', how='inner')\n",
    "    \n",
    "    return(finaldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_premgames function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_premgames (code, player):\n",
    "    base_url = f'https://fbref.com/en/players/{code}/{player}'\n",
    "    html = requests.get(base_url).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    summary = soup.find('table', class_='stats_table sortable min_width')\n",
    "    \n",
    "    comp = summary.find_all('td', attrs={'data-stat': 'comp_level'})\n",
    "    comp_text = [cell.get_text() for cell in comp]\n",
    "    games = summary.find_all('td', attrs={'data-stat': 'games'})\n",
    "    games_text = [cell.get_text() for cell in games]\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Competition': comp_text, \n",
    "        'Games Played': games_text\n",
    "    })\n",
    "    total_games = df[df['Competition'] == '1. Premier League']['Games Played']\n",
    "    total_games = pd.to_numeric(total_games)\n",
    "    prem_games = total_games.sum() - total_games.iloc[-1]\n",
    "    return(prem_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to_csv function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(dataframe):\n",
    "    if isinstance(dataframe, pd.DataFrame):\n",
    "        dataframe.to_csv(os.path.join(nest_folder, ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code specifies the location to place the .csv file into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_folder = (\"Player_Data\")\n",
    "os.makedirs(nest_folder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we actually use the functions above to get the necessary data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diogo Jota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_2324_finaldf = get_data('178ae8f8', '2023-2024', 'Diogo-Jota',  \"Diogo_Teixeira da Silva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_2223_finaldf = get_data('178ae8f8', '2022-2023', 'Diogo-Jota',  \"Diogo_Teixeira da Silva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_2122_finaldf = get_data('178ae8f8', '2021-2022', 'Diogo-Jota',  \"Diogo_Teixeira da Silva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_2021_finaldf = get_data('178ae8f8', '2020-2021', 'Diogo-Jota',  \"Diogo_Teixeira da Silva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_1920_finaldf = get_data('178ae8f8', '2019-2020', 'Diogo-Jota',  \"Diogo_Teixeira da Silva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_1819_finaldf = get_data('178ae8f8', '2018-2019', 'Diogo-Jota',  \"Diogo_Teixeira da Silva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_finaldat = pd.concat([jota_1819_finaldf, jota_1920_finaldf, jota_2021_finaldf, jota_2122_finaldf\n",
    "                            , jota_2223_finaldf, jota_2324_finaldf], join = 'inner', ignore_index = True)\n",
    "jota_finaldat.to_csv(os.path.join(nest_folder, \"jota_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luis Diaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaz_2324_finaldf = get_data('4a1a9578', '2023-2024', 'Luis-Diaz',  \"Luis_Díaz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaz_2223_finaldf = get_data('4a1a9578', '2022-2023', 'Luis-Diaz',  \"Luis_Díaz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaz_2122_finaldf = get_data('4a1a9578', '2021-2022', 'Luis-Diaz',  \"Luis_Díaz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaz_finaldat = pd.concat([diaz_2122_finaldf, diaz_2223_finaldf, diaz_2324_finaldf], join = 'inner', ignore_index = True)\n",
    "diaz_finaldat.to_csv(os.path.join(nest_folder, \"diaz_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cody Gakpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gakpo_2324_finaldf = get_data('1971591f', '2023-2024', 'Cody-Gakpo',  \"Cody_Gakpo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gakpo_2223_finaldf = get_data('1971591f', '2022-2023', 'Cody-Gakpo',  \"Cody_Gakpo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gakpo_finaldat = pd.concat([gakpo_2223_finaldf, gakpo_2324_finaldf], join = 'inner', ignore_index = True)\n",
    "gakpo_finaldat.to_csv(os.path.join(nest_folder, \"gakpo_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darwin Nunez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_2324_finaldf = get_data('4d77b365', '2023-2024', 'Darwin-Nunez',  \"Darwin_Núñez Ribeiro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_2223_finaldf = get_data('4d77b365', '2022-2023', 'Darwin-Nunez',  \"Darwin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_finaldat = pd.concat([darwin_2223_finaldf, darwin_2324_finaldf], join = 'inner', ignore_index = True)\n",
    "darwin_finaldat.to_csv(os.path.join(nest_folder, \"darwin_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Function\n",
    "This new function compile_dat allows us to get all of the data for a single player in one function, instead of having to do it one by one as can be seen above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_dat (code, player, fpl_name, checkgames):\n",
    "    #these are the seasons for which we have fpl data \n",
    "    year_list = ('2023-24', '2022-23', '2021-22', '2020-21', '2019-20', '2018-19', '2017-18')\n",
    "    \n",
    "    #active_years is a list that will store the seasons that a given player was active. The for loop will check to see which years a player was active\n",
    "    #in the prem, and will append this year to the list\n",
    "    active_years = []\n",
    "    for year in year_list: \n",
    "        directory = f'Fantasy-Premier-League/data/{year}/players'\n",
    "        files = os.listdir(directory)\n",
    "        csv_file = [f for f in files if fpl_name in f]\n",
    "        if csv_file:\n",
    "            update_year = year[:5] + '20' + year[5:]\n",
    "            active_years.append(update_year)\n",
    "    \n",
    "    #create an empty dictionary to store all of the dataframes \n",
    "    dataframes = {}\n",
    "    \n",
    "    #for each season a player was active, the get_data function from above is uesd to add the data for that season to the dataframes dictionary\n",
    "    for year in active_years: \n",
    "        dataframes[year] = get_data(code, year, player, fpl_name)\n",
    "        #1 minute pause in between each iteration, to ensure that we don't get banned from FBref\n",
    "        time.sleep(60)\n",
    "    \n",
    "    #concatenate all of the dataframes, and return one final concatenated dataframe\n",
    "    finaldf = pd.concat(dataframes.values(), join = \"inner\", ignore_index = True)\n",
    "    \n",
    "    if checkgames:\n",
    "        games_played = get_premgames(code, player)\n",
    "        if games_played == finaldf.shape[0]:\n",
    "            return(finaldf)\n",
    "        else:\n",
    "            return(print('The number of Premier League games played by ' + player + ' does not match the number of rows in the dataframe'))\n",
    "    else: \n",
    "        return(finaldf)\n",
    "\n",
    "#note that the to_csv code is not included in this function, because there are certain players whose names were changed in between seasons \n",
    "#(e.g. Diogo Teixeira da Silva to Diogo Jota). In these cases, we need to use the compile function twice to get all of the data, before concatenating\n",
    "#and then finally exporting to csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arsenal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "saka_finaldat = compile_dat('bc7dc64d', 'Bukayo-Saka', 'Bukayo')\n",
    "saka_finaldat.to_csv(os.path.join(nest_folder, \"saka_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "havertz_finaldat = compile_dat('fed7cb61', 'Kai-Havertz', 'Kai_Havertz')\n",
    "havertz_finaldat.to_csv(os.path.join(nest_folder, \"havertz_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "jesus_finaldat = compile_dat('b66315ae', 'Gabriel-Jesus', 'de Jesus')\n",
    "jesus_finaldat.to_csv(os.path.join(nest_folder, \"jesus_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trossard_finaldat = compile_dat('38ceb24a', 'Leandro-Trossard', 'Leandro_Trossard')\n",
    "trossard_finaldat.to_csv(os.path.join(nest_folder, \"trossard_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "martinelli_finaldat = compile_dat('48a5a5d6', 'Gabriel-Martinelli', 'Martinelli')\n",
    "martinelli_finaldat.to_csv(os.path.join(nest_folder, \"martinelli_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "odegaard_finaldat = compile_dat('79300479', 'Martin-Odegaard', 'Ødegaard')\n",
    "odegaard_finaldat.to_csv(os.path.join(nest_folder, \"odegaard_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sterling_finaldat = compile_dat('b400bde0', 'Raheem-Sterling', 'Raheem_Sterling')\n",
    "sterling_finaldat.to_csv(os.path.join(nest_folder, \"sterling_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jorginho_finaldat = compile_dat('45db685d', 'Jorginho', 'Jorge Luiz_Frello', checkgames = True)\n",
    "if isinstance(jorginho_finaldat, pd.DataFrame):\n",
    "    jorginho_finaldat.to_csv(os.path.join(nest_folder, \"jorginho_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_finaldat = compile_dat('1c7012b8', 'Declan-Rice', 'Declan_Rice', checkgames = True)\n",
    "if isinstance(rice_finaldat, pd.DataFrame):\n",
    "    rice_finaldat.to_csv(os.path.join(nest_folder, \"rice_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partey_finaldat = compile_dat('529f49ab', 'Thomas-Partey', 'Thomas_Partey', checkgames = True)\n",
    "if isinstance(partey_finaldat, pd.DataFrame):\n",
    "    partey_finaldat.to_csv(os.path.join(nest_folder, \"partey_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aston Villa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "duran_finaldat = compile_dat('414184f7', 'Jhon-Duran', 'Jhon', checkgames=True)\n",
    "duran_finaldat.to_csv(os.path.join(nest_folder, \"duran_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "watkins_finaldat = compile_dat('aed3a70f', 'Ollie-Watkins', 'Ollie_Watkins', checkgames=True)\n",
    "if isinstance(watkins_finaldat, pd.DataFrame):\n",
    "    watkins_finaldat.to_csv(os.path.join(nest_folder, \"watkins_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramsey_finaldat = compile_dat('1544f145', 'Jacob-Ramsey', 'Jacob_Ramsey', checkgames = True)\n",
    "if isinstance(ramsey_finaldat, pd.DataFrame):\n",
    "    ramsey_finaldat.to_csv(os.path.join(nest_folder, \"ramsey_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcginn_finaldat = compile_dat('90f91999', 'John-McGinn', 'John_McGinn', checkgames = False)\n",
    "if isinstance(mcginn_finaldat, pd.DataFrame):\n",
    "    mcginn_finaldat.to_csv(os.path.join(nest_folder, \"mcginn_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "bailey_finaldat = compile_dat('3a233281', 'Leon-Bailey', 'Leon_Bailey', checkgames = True)\n",
    "if isinstance(bailey_finaldat, pd.DataFrame):\n",
    "    bailey_finaldat.to_csv(os.path.join(nest_folder, \"bailey_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "buendia_finaldat = compile_dat('66b76d44', 'Emi-Buendia', 'Emiliano_Buen', checkgames = True)\n",
    "if isinstance(buendia_finaldat, pd.DataFrame):\n",
    "    buendia_finaldat.to_csv(os.path.join(nest_folder, \"buendia_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tielemans_finaldat = compile_dat('56f7a928', 'Youri-Tielemans', 'Youri_Tielemans', checkgames = True)\n",
    "if isinstance(tielemans_finaldat, pd.DataFrame):\n",
    "    tielemans_finaldat.to_csv(os.path.join(nest_folder, \"tielemans_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m barkley_finaldat \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_dat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m3a24769f\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRoss-Barkley\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRoss_Barkley\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckgames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(barkley_finaldat, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m      3\u001b[0m     barkley_finaldat\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(nest_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarkley_finaldat.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[55], line 21\u001b[0m, in \u001b[0;36mcompile_dat\u001b[0;34m(code, player, fpl_name, checkgames)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#for each season a player was active, the get_data function from above is uesd to add the data for that season to the dataframes dictionary\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m active_years: \n\u001b[0;32m---> 21\u001b[0m     dataframes[year] \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpl_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m#1 minute pause in between each iteration, to ensure that we don't get banned from FBref\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m60\u001b[39m)\n",
      "Cell \u001b[0;32mIn[34], line 16\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(code, year_range, player, fpl_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m data_possession \u001b[38;5;241m=\u001b[39m get_url_final(code, year_range, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpossession\u001b[39m\u001b[38;5;124m'\u001b[39m, player)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m################################################################\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#getting the data for the necessary columns\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m##### summary data #####\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#misc data \u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m date \u001b[38;5;241m=\u001b[39m \u001b[43mget_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m day \u001b[38;5;241m=\u001b[39m get_dat(data_summary,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdayofweek\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m matchweek \u001b[38;5;241m=\u001b[39m get_matchweek(data_summary, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mround\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mget_date\u001b[0;34m(dat, col)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_date\u001b[39m(dat, col):\n\u001b[1;32m      9\u001b[0m     coldat \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m row\u001b[38;5;241m.\u001b[39mattrs:\n\u001b[1;32m     12\u001b[0m             coldat\u001b[38;5;241m.\u001b[39mappend(row\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mth\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata-stat\u001b[39m\u001b[38;5;124m'\u001b[39m: col})\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "barkley_finaldat = compile_dat('3a24769f', 'Ross-Barkley', 'Ross_Barkley', checkgames = True)\n",
    "if isinstance(barkley_finaldat, pd.DataFrame):\n",
    "    barkley_finaldat.to_csv(os.path.join(nest_folder, \"barkley_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onana_finaldat = compile_dat('828657ff', 'Amadou-Onana', 'Amadou_Onana', checkgames = True)\n",
    "if isinstance(onana_finaldat, pd.DataFrame):\n",
    "    onana_finaldat.to_csv(os.path.join(nest_folder, \"onana_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rogers_finaldat = compile_dat('2e5915f1', 'Morgan-Rogers', 'Morgan_Rogers', checkgames = True)\n",
    "if isinstance(rogers_finaldat, pd.DataFrame):\n",
    "    rogers_finaldat.to_csv(os.path.join(nest_folder, \"rogers_finaldat.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
