{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd \n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_url_final function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function just gets the html code that we need to scrape for data, updated version that is not specific to salah \n",
    "def get_url_final(code, year_range, category, player):\n",
    "    base_url = 'https://fbref.com/en/players/{}/matchlogs/{}/c9/{}/{}-Match-Logs'\n",
    "    url = base_url.format(code, year_range, category, player)\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    html_filtered = soup.find('tbody')\n",
    "    return(html_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_dat, get_date and get_matchweek functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dat(dat, col):\n",
    "    coldat = []\n",
    "    for row in dat.find_all('tr'):\n",
    "        if not row.attrs:\n",
    "            coldat.append(row.find('td', {'data-stat': col}).text)\n",
    "    return (coldat)   \n",
    "\n",
    "def get_date(dat, col):\n",
    "    coldat = []\n",
    "    for row in dat.find_all('tr'):\n",
    "        if not row.attrs:\n",
    "            coldat.append(row.find('th', {'data-stat': col}).text)\n",
    "    return (coldat)   \n",
    "\n",
    "def get_matchweek(dat, col):\n",
    "    coldat = []\n",
    "    for row in dat.find_all('tr'):\n",
    "        if not row.attrs:\n",
    "            coldat.append(row.find('td', {'data-stat': col}).text)\n",
    "    coldat = [coldat.replace('Matchweek ', '') for coldat in coldat]\n",
    "    return(coldat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, we want to modify the function above, to allow us to get any players data that we want, not just salah\n",
    "\n",
    "def get_data(code, year_range, player, fpl_name):\n",
    "    data_summary = get_url_final(code, year_range, '', player)\n",
    "    \n",
    "    #this if statement is checking whether or not this player actually has data for the particular year. In the case that they do not actually have\n",
    "    #data for this year, just return an empty dataframe \n",
    "    if not data_summary:\n",
    "        empty = pd.DataFrame()\n",
    "        return(empty)\n",
    "    \n",
    "    data_passing = get_url_final(code, year_range, 'passing', player)\n",
    "    data_passingtype = get_url_final(code, year_range, 'passing_types', player)\n",
    "    data_gca = get_url_final(code, year_range, 'gca', player)\n",
    "    data_defense = get_url_final(code, year_range, 'defense', player)\n",
    "    data_possession = get_url_final(code, year_range, 'possession', player)\n",
    "    \n",
    "    ################################################################\n",
    "    #getting the data for the necessary columns\n",
    "    \n",
    "    ##### summary data #####\n",
    "    #misc data \n",
    "    date = get_date(data_summary, 'date')\n",
    "    day = get_dat(data_summary,'dayofweek')\n",
    "    matchweek = get_matchweek(data_summary, 'round')\n",
    "    venue = get_dat(data_summary, 'venue')\n",
    "    result = get_dat(data_summary, 'result')\n",
    "    team = get_dat(data_summary, 'team')\n",
    "    opponent = get_dat(data_summary, 'opponent')\n",
    "    start = get_dat(data_summary, 'game_started')\n",
    "    position = get_dat(data_summary, 'position')\n",
    "    mins = get_dat(data_summary, 'minutes')\n",
    "\n",
    "    #performance data\n",
    "    goals = get_dat(data_summary, 'goals')\n",
    "    assist = get_dat(data_summary, 'assists')\n",
    "    pen_goals = get_dat(data_summary, 'pens_made')\n",
    "    pen_attempted = get_dat(data_summary, 'pens_att')\n",
    "    shots = get_dat(data_summary, 'shots')\n",
    "    sot = get_dat(data_summary, 'shots_on_target')\n",
    "    yellow = get_dat(data_summary, 'cards_yellow')\n",
    "    red = get_dat(data_summary, 'cards_red')\n",
    "    touches = get_dat(data_summary, 'touches')\n",
    "    tackles = get_dat(data_summary, 'tackles')\n",
    "    interceptions = get_dat(data_summary, 'interceptions')\n",
    "    blocks = get_dat(data_summary, 'blocks')\n",
    "\n",
    "    #expected performance metrics\n",
    "    xg = get_dat(data_summary, 'xg')\n",
    "    npxg = get_dat(data_summary, 'npxg')\n",
    "    xag = get_dat(data_summary, 'xg_assist')\n",
    "\n",
    "    #shot creating actions\n",
    "    sca = get_dat(data_summary, 'sca')\n",
    "    gca = get_dat(data_summary, 'gca')\n",
    "\n",
    "    #passes\n",
    "    passes_completed = get_dat(data_summary, 'passes_completed')\n",
    "    passes_attempted = get_dat(data_summary, 'passes')\n",
    "    prg_passes = get_dat(data_summary, 'progressive_passes')\n",
    "\n",
    "    #carries \n",
    "    carries = get_dat(data_summary, 'carries')\n",
    "    prg_carries = get_dat(data_summary, 'progressive_carries')\n",
    "\n",
    "    #take-ons\n",
    "    takeon_att = get_dat(data_summary, 'take_ons')\n",
    "    takeon_suc = get_dat(data_summary, 'take_ons_won')\n",
    "    \n",
    "    ##### passing data #####\n",
    "    #total\n",
    "    pass_distance = get_dat(data_passing, 'passes_total_distance')\n",
    "    prg_pass_distance = get_dat(data_passing, 'passes_progressive_distance')\n",
    "\n",
    "    #short\n",
    "    short_pass_completed = get_dat(data_passing, 'passes_completed_short')\n",
    "    short_pass_attempted = get_dat(data_passing, 'passes_short')\n",
    "\n",
    "    #medium \n",
    "    med_pass_completed = get_dat(data_passing, 'passes_completed_medium')\n",
    "    med_pass_attempted = get_dat(data_passing, 'passes_medium')\n",
    "\n",
    "    #long\n",
    "    long_pass_completed = get_dat(data_passing, 'passes_completed_long')\n",
    "    long_pass_attempted = get_dat(data_passing, 'passes_long')\n",
    "\n",
    "    #misc\n",
    "    xa = get_dat(data_passing, 'pass_xa')\n",
    "    keypass = get_dat(data_passing, 'assisted_shots')\n",
    "    finalthird_pass = get_dat(data_passing, 'passes_into_final_third')\n",
    "    penaltyarea_pass = get_dat(data_passing, 'passes_into_penalty_area')\n",
    "    penaltyarea_cross = get_dat(data_passing, 'crosses_into_penalty_area')\n",
    "    \n",
    "    \n",
    "    ##### passing types data #####\n",
    "    live_pass = get_dat(data_passingtype, 'passes_live')\n",
    "    dead_pass = get_dat(data_passingtype, 'passes_dead')\n",
    "    freekick_pass = get_dat(data_passingtype, 'passes_free_kicks')\n",
    "    through_balls = get_dat(data_passingtype, 'through_balls')\n",
    "    switches = get_dat(data_passingtype, 'passes_switches')\n",
    "    crosses = get_dat(data_passingtype, 'crosses')\n",
    "    throwin = get_dat(data_passingtype, 'throw_ins')\n",
    "    corners = get_dat(data_passingtype, 'corner_kicks')\n",
    "    offside_pass = get_dat(data_passingtype, 'passes_offsides')\n",
    "    \n",
    "    \n",
    "    ##### gca data #####\n",
    "    #sca types \n",
    "    live_sca = get_dat(data_gca, 'sca_passes_live')\n",
    "    deadball_sca = get_dat(data_gca, 'sca_passes_dead')\n",
    "    takeons_sca = get_dat(data_gca, 'sca_take_ons')\n",
    "    shots_sca = get_dat(data_gca, 'sca_shots')\n",
    "    fouls_sca = get_dat(data_gca, 'sca_fouled')\n",
    "    defense_sca = get_dat(data_gca, 'sca_defense')\n",
    "\n",
    "    #gca types \n",
    "    live_gca = get_dat(data_gca, 'gca_passes_live')\n",
    "    deadball_gca = get_dat(data_gca, 'gca_passes_dead')\n",
    "    takeons_gca = get_dat(data_gca, 'gca_take_ons')\n",
    "    shots_gca = get_dat(data_gca, 'gca_shots')\n",
    "    fouls_gca = get_dat(data_gca, 'gca_fouled')\n",
    "    defense_gca = get_dat(data_gca, 'gca_defense')\n",
    "    \n",
    "    \n",
    "    ##### defensive data ######\n",
    "    #tackles\n",
    "    tackles_won = get_dat(data_defense,'tackles_won')\n",
    "    tackles_def = get_dat(data_defense, 'tackles_def_3rd')\n",
    "    tackles_mid = get_dat(data_defense, 'tackles_mid_3rd')\n",
    "    tackles_att = get_dat(data_defense, 'tackles_att_3rd')\n",
    "\n",
    "    #challenges \n",
    "    dribblers_tackled = get_dat(data_defense, 'challenge_tackles')\n",
    "    dribbles_challenged = get_dat(data_defense, 'challenges')\n",
    "    challenges_lost = get_dat(data_defense, 'challenges_lost')\n",
    "\n",
    "    #blocks \n",
    "    shots_blocked = get_dat(data_defense, 'blocked_shots')\n",
    "    pass_blocked = get_dat(data_defense, 'blocked_passes')\n",
    "    clearances = get_dat(data_defense, 'clearances')\n",
    "    def_errors = get_dat(data_defense, 'errors')\n",
    "    \n",
    "    \n",
    "    ##### possession data #####\n",
    "    #touches \n",
    "    def_penarea_touches = get_dat(data_possession, 'touches_def_pen_area')\n",
    "    def_third_touches = get_dat(data_possession, 'touches_def_3rd')\n",
    "    mid_third_touches = get_dat(data_possession, 'touches_mid_3rd')\n",
    "    att_third_touches = get_dat(data_possession, 'touches_att_3rd')\n",
    "    pen_area_touches = get_dat(data_possession, 'touches_att_pen_area')\n",
    "\n",
    "    #carries\n",
    "    carry_distance = get_dat(data_possession, 'carries_distance')\n",
    "    prg_carry_distance = get_dat(data_possession, 'carries_progressive_distance')\n",
    "    final_third_carries = get_dat(data_possession, 'carries_into_final_third')\n",
    "    pen_area_carries = get_dat(data_possession, 'carries_into_penalty_area')\n",
    "    miscontrols = get_dat(data_possession, 'miscontrols')\n",
    "    dispossesed = get_dat(data_possession, 'dispossessed')\n",
    "\n",
    "    #receiving \n",
    "    pass_received = get_dat(data_possession, 'passes_received')\n",
    "    prg_pass_received = get_dat(data_possession, 'progressive_passes_received')\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    #creating dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'Date': date,\n",
    "        'Day': day,\n",
    "        'Matchweek': matchweek,\n",
    "        'Venue': venue,\n",
    "        'Result': result,\n",
    "        'Team': team,\n",
    "        'Opponent': opponent, \n",
    "        'Start': start, \n",
    "        'Position': position,\n",
    "        'Minutes Played': mins, \n",
    "        'Goals': goals, \n",
    "        'Assists': assist, \n",
    "        'Penalties Scored': pen_goals, \n",
    "        'Penalties Attempted': pen_attempted, \n",
    "        'Shots': shots, \n",
    "        'Shots on Target': sot, \n",
    "        'Yellow Cards': yellow, \n",
    "        'Red Cards': red, \n",
    "        'Touches': touches, \n",
    "        'Tackles': tackles,\n",
    "        'Interceptions': interceptions, \n",
    "        'Blocks': blocks, \n",
    "        'xG': xg,\n",
    "        'npxG': npxg,\n",
    "        'xAG': xag, \n",
    "        'Shot Creating Actions': sca, \n",
    "        'Goal Creating Actions': gca, \n",
    "        'Passes Completed': passes_completed, \n",
    "        'Passes Attempted': passes_attempted, \n",
    "        'Progressive Passes': prg_passes,\n",
    "        'Carries': carries, \n",
    "        'Progressive Carries': prg_carries, \n",
    "        'Take-ons Attempted': takeon_att, \n",
    "        'Successful Take-ons': takeon_suc,\n",
    "        \n",
    "        'Passing Distance': pass_distance, \n",
    "        'Progressive Passing Distance': prg_pass_distance,\n",
    "        'Short Passes Completed' : short_pass_completed,\n",
    "        'Short Passes Attempted': short_pass_attempted,\n",
    "        'Medium Passes Completed': med_pass_completed,\n",
    "        'Medium Passes Attempted': med_pass_attempted,\n",
    "        'Long Passes Completed': long_pass_completed,\n",
    "        'Long Passes Attempted': long_pass_attempted,\n",
    "        'Expected Assists': xa,\n",
    "        'Key Passes': keypass,\n",
    "        'Passes into Final Third': finalthird_pass,\n",
    "        'Passes into Penalty Area': penaltyarea_pass,\n",
    "        'Crosses into Penalty Area': penaltyarea_cross,\n",
    "    \n",
    "        'Live Pass': live_pass,\n",
    "        'Dead Pass': dead_pass,\n",
    "        'Free Kick Pass': freekick_pass,\n",
    "        'Through Balls': through_balls,\n",
    "        'Switches': switches,\n",
    "        'Crosses': crosses,\n",
    "        'Throw Ins Taken': throwin,\n",
    "        'Corners Taken': corners,\n",
    "        'Passes Offside': offside_pass,\n",
    "    \n",
    "        'Live SCA': live_sca,\n",
    "        'Deadball SCA': deadball_sca,\n",
    "        'Take-on SCA': takeons_sca,\n",
    "        'Shot SCA': shots_sca,\n",
    "        'Foul SCA': fouls_sca,\n",
    "        'Defense SCA': defense_sca,\n",
    "    \n",
    "        'Live GCA': live_gca,\n",
    "        'Deadball GCA': deadball_gca,\n",
    "        'Take-on GCA': takeons_gca,\n",
    "        'Shot GCA': shots_gca,\n",
    "        'Foul GCA': fouls_gca,\n",
    "        'Defense GCA': defense_gca,\n",
    "    \n",
    "        'Tackles Won': tackles_won,\n",
    "        'Defensive Third Tackles': tackles_def,\n",
    "        'Middle Third Tackles': tackles_mid,\n",
    "        'Attacking Third Tackles': tackles_att,\n",
    "        'Dribblers Tackled': dribblers_tackled,\n",
    "        'Dribblers Tackled Attempts': dribbles_challenged,\n",
    "        'Challenges Lost': challenges_lost,\n",
    "        'Shots Blocked': shots_blocked,\n",
    "        'Passes Blocked': pass_blocked,\n",
    "        'Clearances': clearances,\n",
    "        'Defensive Errors': def_errors,\n",
    "    \n",
    "        'Defensive Penalty Area Touches': def_penarea_touches,\n",
    "        'Defensive Third Touches': def_third_touches,\n",
    "        'Middle Third Touches': mid_third_touches,\n",
    "        'Attacking Third Touches': att_third_touches,\n",
    "        'Penalty Area Touches': pen_area_touches,\n",
    "        'Carry Distance': carry_distance,\n",
    "        'Progressive Carry Distance': prg_carry_distance,\n",
    "        'Final Third Carries': final_third_carries,\n",
    "        'Carries into Penalty Area': pen_area_carries,\n",
    "        'Miscontrols': miscontrols,\n",
    "        'Dispossessed': dispossesed,\n",
    "        'Passes Received': pass_received,\n",
    "        'Progressive Passes Received': prg_pass_received\n",
    "    })\n",
    "    \n",
    "    #modifying data types\n",
    "    df = df.astype({\n",
    "        'Date': 'datetime64[ns]',\n",
    "        'Day': 'object',\n",
    "        'Matchweek': 'int64',\n",
    "        'Venue': 'object',\n",
    "        'Result': 'object',\n",
    "        'Team': 'object',\n",
    "        'Opponent': 'object', \n",
    "        'Start': 'object', \n",
    "        'Position': 'object',\n",
    "        'Minutes Played': 'int64', \n",
    "        'Goals': 'int64', \n",
    "        'Assists': 'int64', \n",
    "        'Penalties Scored': 'int64', \n",
    "        'Penalties Attempted': 'int64', \n",
    "        'Shots': 'int64', \n",
    "        'Shots on Target': 'int64', \n",
    "        'Yellow Cards': 'int64', \n",
    "        'Red Cards': 'int64', \n",
    "        'Touches': 'int64', \n",
    "        'Tackles': 'int64',\n",
    "        'Interceptions': 'int64', \n",
    "        'Blocks': 'int64', \n",
    "        'xG': 'float64',\n",
    "        'npxG': 'float64',\n",
    "        'xAG': 'float64', \n",
    "        'Shot Creating Actions': 'int64', \n",
    "        'Goal Creating Actions': 'int64', \n",
    "        'Passes Completed': 'int64', \n",
    "        'Passes Attempted': 'int64', \n",
    "        'Progressive Passes': 'int64',\n",
    "        'Carries': 'int64', \n",
    "        'Progressive Carries': 'int64', \n",
    "        'Take-ons Attempted': 'int64', \n",
    "        'Successful Take-ons': 'int64',\n",
    "        \n",
    "        'Short Passes Completed' : 'int64',\n",
    "        'Short Passes Attempted': 'int64',\n",
    "        'Medium Passes Completed': 'int64',\n",
    "        'Medium Passes Attempted': 'int64',\n",
    "        'Long Passes Completed': 'int64',\n",
    "        'Long Passes Attempted': 'int64',\n",
    "        'Expected Assists': 'float64',\n",
    "        'Key Passes': 'int64',\n",
    "        'Passes into Final Third': 'int64',\n",
    "        'Passes into Penalty Area': 'int64',\n",
    "        'Crosses into Penalty Area': 'int64',\n",
    "    \n",
    "        'Live Pass': 'int64',\n",
    "        'Dead Pass': 'int64',\n",
    "        'Free Kick Pass': 'int64',\n",
    "        'Through Balls': 'int64',\n",
    "        'Switches': 'int64',\n",
    "        'Crosses': 'int64',\n",
    "        'Throw Ins Taken': 'int64',\n",
    "        'Corners Taken': 'int64',\n",
    "        'Passes Offside': 'int64',\n",
    "    \n",
    "        'Live SCA': 'int64',\n",
    "        'Deadball SCA': 'int64',\n",
    "        'Take-on SCA': 'int64',\n",
    "        'Shot SCA': 'int64',\n",
    "        'Foul SCA': 'int64',\n",
    "        'Defense SCA': 'int64',\n",
    "    \n",
    "        'Live GCA': 'int64',\n",
    "        'Deadball GCA': 'int64',\n",
    "        'Take-on GCA': 'int64',\n",
    "        'Shot GCA': 'int64',\n",
    "        'Foul GCA': 'int64',\n",
    "        'Defense GCA': 'int64',\n",
    "    \n",
    "        'Tackles Won': 'int64',\n",
    "        'Defensive Third Tackles': 'int64',\n",
    "        'Middle Third Tackles': 'int64',\n",
    "        'Attacking Third Tackles': 'int64',\n",
    "        'Dribblers Tackled': 'int64',\n",
    "        'Dribblers Tackled Attempts': 'int64',\n",
    "        'Challenges Lost': 'int64',\n",
    "        'Shots Blocked': 'int64',\n",
    "        'Passes Blocked': 'int64',\n",
    "        'Clearances': 'int64',\n",
    "        'Defensive Errors': 'int64',\n",
    "    \n",
    "        'Defensive Penalty Area Touches': 'int64',\n",
    "        'Defensive Third Touches': 'int64',\n",
    "        'Middle Third Touches': 'int64',\n",
    "        'Attacking Third Touches': 'int64',\n",
    "        'Penalty Area Touches': 'int64',\n",
    "        'Carry Distance': 'float64',\n",
    "        'Progressive Carry Distance': 'float64',\n",
    "        'Final Third Carries': 'int64',\n",
    "        'Carries into Penalty Area': 'int64',\n",
    "        'Miscontrols': 'int64',\n",
    "        'Dispossessed': 'int64',\n",
    "        'Passes Received': 'int64',\n",
    "        'Progressive Passes Received': 'int64'\n",
    "    })\n",
    "    \n",
    "    #changing date column data type \n",
    "    df['Date'] = df['Date'].dt.date\n",
    "    \n",
    "    ###############################################################################\n",
    "    \n",
    "    #now we want to get the fpl data \n",
    "    start_year = year_range[:4] #getting the whole of the first year \n",
    "    end_year = year_range[-2:]\n",
    "    format_year = f'{start_year}-{end_year}'\n",
    "    directory = f'Fantasy-Premier-League/data/{format_year}/players'\n",
    "    files = os.listdir(directory)\n",
    "    csv_file = [f for f in files if fpl_name in f]\n",
    "    fpldf = pd.read_csv(os.path.join(directory, csv_file[0]) + '/gw.csv')\n",
    "\n",
    "    #some of the columns are duplicated (from the webscraped data), so we want to remove these \n",
    "    fpldf = fpldf.drop(['assists', 'expected_assists', 'expected_goal_involvements', 'expected_goals', 'fixture',\n",
    "                                          'goals_conceded', 'goals_scored', 'penalties_missed', 'penalties_saved', 'red_cards'\n",
    "                                          ,'team_a_score', 'team_h_score', 'was_home', 'yellow_cards', 'element', 'opponent_team', 'starts'\n",
    "                                          ,'expected_goals_conceded'], axis=1, \n",
    "                       errors = 'ignore')\n",
    "\n",
    "    #we now want to change the 'kickoff time' feature into a datetime object \n",
    "    fpldf['kickoff_time'] = pd.to_datetime(fpldf['kickoff_time'])\n",
    "\n",
    "    #creating new column, which is just the kickoff date \n",
    "    fpldf['kickoff_date'] = fpldf['kickoff_time'].dt.date\n",
    "    \n",
    "    finaldf = pd.merge(df, fpldf, left_on='Date', right_on='kickoff_date', how='inner')\n",
    "    \n",
    "    return(finaldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is just to use the get_data function to create a representative dataframe, with the purpose being just to get the column names. This is why \n",
    "#we have to specify another get_data function below (get_data_final), which implements functionality that deals with players who have empty pages in \n",
    "#Fbref\n",
    "test = get_data('66b76d44', '2022-2023', 'Emi-Buendia', 'Emiliano_Buen')\n",
    "column_names = test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the final version of get_data, which includes additional functionality to deal with players who hav eempty pages in Fbref\n",
    "def get_data_final(code, year_range, player, fpl_name):\n",
    "    data_summary = get_url_final(code, year_range, '', player)\n",
    "    \n",
    "    #this if statement is checking whether or not this player actually has data for the particular year. In the case that they do not actually have\n",
    "    #data for this year, just return an empty dataframe \n",
    "    if not data_summary:\n",
    "        empty = pd.DataFrame(columns = column_names)\n",
    "        return(empty)\n",
    "    \n",
    "    data_passing = get_url_final(code, year_range, 'passing', player)\n",
    "    data_passingtype = get_url_final(code, year_range, 'passing_types', player)\n",
    "    data_gca = get_url_final(code, year_range, 'gca', player)\n",
    "    data_defense = get_url_final(code, year_range, 'defense', player)\n",
    "    data_possession = get_url_final(code, year_range, 'possession', player)\n",
    "    \n",
    "    ################################################################\n",
    "    #getting the data for the necessary columns\n",
    "    \n",
    "    ##### summary data #####\n",
    "    #misc data \n",
    "    date = get_date(data_summary, 'date')\n",
    "    day = get_dat(data_summary,'dayofweek')\n",
    "    matchweek = get_matchweek(data_summary, 'round')\n",
    "    venue = get_dat(data_summary, 'venue')\n",
    "    result = get_dat(data_summary, 'result')\n",
    "    team = get_dat(data_summary, 'team')\n",
    "    opponent = get_dat(data_summary, 'opponent')\n",
    "    start = get_dat(data_summary, 'game_started')\n",
    "    position = get_dat(data_summary, 'position')\n",
    "    mins = get_dat(data_summary, 'minutes')\n",
    "\n",
    "    #performance data\n",
    "    goals = get_dat(data_summary, 'goals')\n",
    "    assist = get_dat(data_summary, 'assists')\n",
    "    pen_goals = get_dat(data_summary, 'pens_made')\n",
    "    pen_attempted = get_dat(data_summary, 'pens_att')\n",
    "    shots = get_dat(data_summary, 'shots')\n",
    "    sot = get_dat(data_summary, 'shots_on_target')\n",
    "    yellow = get_dat(data_summary, 'cards_yellow')\n",
    "    red = get_dat(data_summary, 'cards_red')\n",
    "    touches = get_dat(data_summary, 'touches')\n",
    "    tackles = get_dat(data_summary, 'tackles')\n",
    "    interceptions = get_dat(data_summary, 'interceptions')\n",
    "    blocks = get_dat(data_summary, 'blocks')\n",
    "\n",
    "    #expected performance metrics\n",
    "    xg = get_dat(data_summary, 'xg')\n",
    "    npxg = get_dat(data_summary, 'npxg')\n",
    "    xag = get_dat(data_summary, 'xg_assist')\n",
    "\n",
    "    #shot creating actions\n",
    "    sca = get_dat(data_summary, 'sca')\n",
    "    gca = get_dat(data_summary, 'gca')\n",
    "\n",
    "    #passes\n",
    "    passes_completed = get_dat(data_summary, 'passes_completed')\n",
    "    passes_attempted = get_dat(data_summary, 'passes')\n",
    "    prg_passes = get_dat(data_summary, 'progressive_passes')\n",
    "\n",
    "    #carries \n",
    "    carries = get_dat(data_summary, 'carries')\n",
    "    prg_carries = get_dat(data_summary, 'progressive_carries')\n",
    "\n",
    "    #take-ons\n",
    "    takeon_att = get_dat(data_summary, 'take_ons')\n",
    "    takeon_suc = get_dat(data_summary, 'take_ons_won')\n",
    "    \n",
    "    ##### passing data #####\n",
    "    #total\n",
    "    pass_distance = get_dat(data_passing, 'passes_total_distance')\n",
    "    prg_pass_distance = get_dat(data_passing, 'passes_progressive_distance')\n",
    "\n",
    "    #short\n",
    "    short_pass_completed = get_dat(data_passing, 'passes_completed_short')\n",
    "    short_pass_attempted = get_dat(data_passing, 'passes_short')\n",
    "\n",
    "    #medium \n",
    "    med_pass_completed = get_dat(data_passing, 'passes_completed_medium')\n",
    "    med_pass_attempted = get_dat(data_passing, 'passes_medium')\n",
    "\n",
    "    #long\n",
    "    long_pass_completed = get_dat(data_passing, 'passes_completed_long')\n",
    "    long_pass_attempted = get_dat(data_passing, 'passes_long')\n",
    "\n",
    "    #misc\n",
    "    xa = get_dat(data_passing, 'pass_xa')\n",
    "    keypass = get_dat(data_passing, 'assisted_shots')\n",
    "    finalthird_pass = get_dat(data_passing, 'passes_into_final_third')\n",
    "    penaltyarea_pass = get_dat(data_passing, 'passes_into_penalty_area')\n",
    "    penaltyarea_cross = get_dat(data_passing, 'crosses_into_penalty_area')\n",
    "    \n",
    "    \n",
    "    ##### passing types data #####\n",
    "    live_pass = get_dat(data_passingtype, 'passes_live')\n",
    "    dead_pass = get_dat(data_passingtype, 'passes_dead')\n",
    "    freekick_pass = get_dat(data_passingtype, 'passes_free_kicks')\n",
    "    through_balls = get_dat(data_passingtype, 'through_balls')\n",
    "    switches = get_dat(data_passingtype, 'passes_switches')\n",
    "    crosses = get_dat(data_passingtype, 'crosses')\n",
    "    throwin = get_dat(data_passingtype, 'throw_ins')\n",
    "    corners = get_dat(data_passingtype, 'corner_kicks')\n",
    "    offside_pass = get_dat(data_passingtype, 'passes_offsides')\n",
    "    \n",
    "    \n",
    "    ##### gca data #####\n",
    "    #sca types \n",
    "    live_sca = get_dat(data_gca, 'sca_passes_live')\n",
    "    deadball_sca = get_dat(data_gca, 'sca_passes_dead')\n",
    "    takeons_sca = get_dat(data_gca, 'sca_take_ons')\n",
    "    shots_sca = get_dat(data_gca, 'sca_shots')\n",
    "    fouls_sca = get_dat(data_gca, 'sca_fouled')\n",
    "    defense_sca = get_dat(data_gca, 'sca_defense')\n",
    "\n",
    "    #gca types \n",
    "    live_gca = get_dat(data_gca, 'gca_passes_live')\n",
    "    deadball_gca = get_dat(data_gca, 'gca_passes_dead')\n",
    "    takeons_gca = get_dat(data_gca, 'gca_take_ons')\n",
    "    shots_gca = get_dat(data_gca, 'gca_shots')\n",
    "    fouls_gca = get_dat(data_gca, 'gca_fouled')\n",
    "    defense_gca = get_dat(data_gca, 'gca_defense')\n",
    "    \n",
    "    \n",
    "    ##### defensive data ######\n",
    "    #tackles\n",
    "    tackles_won = get_dat(data_defense,'tackles_won')\n",
    "    tackles_def = get_dat(data_defense, 'tackles_def_3rd')\n",
    "    tackles_mid = get_dat(data_defense, 'tackles_mid_3rd')\n",
    "    tackles_att = get_dat(data_defense, 'tackles_att_3rd')\n",
    "\n",
    "    #challenges \n",
    "    dribblers_tackled = get_dat(data_defense, 'challenge_tackles')\n",
    "    dribbles_challenged = get_dat(data_defense, 'challenges')\n",
    "    challenges_lost = get_dat(data_defense, 'challenges_lost')\n",
    "\n",
    "    #blocks \n",
    "    shots_blocked = get_dat(data_defense, 'blocked_shots')\n",
    "    pass_blocked = get_dat(data_defense, 'blocked_passes')\n",
    "    clearances = get_dat(data_defense, 'clearances')\n",
    "    def_errors = get_dat(data_defense, 'errors')\n",
    "    \n",
    "    \n",
    "    ##### possession data #####\n",
    "    #touches \n",
    "    def_penarea_touches = get_dat(data_possession, 'touches_def_pen_area')\n",
    "    def_third_touches = get_dat(data_possession, 'touches_def_3rd')\n",
    "    mid_third_touches = get_dat(data_possession, 'touches_mid_3rd')\n",
    "    att_third_touches = get_dat(data_possession, 'touches_att_3rd')\n",
    "    pen_area_touches = get_dat(data_possession, 'touches_att_pen_area')\n",
    "\n",
    "    #carries\n",
    "    carry_distance = get_dat(data_possession, 'carries_distance')\n",
    "    prg_carry_distance = get_dat(data_possession, 'carries_progressive_distance')\n",
    "    final_third_carries = get_dat(data_possession, 'carries_into_final_third')\n",
    "    pen_area_carries = get_dat(data_possession, 'carries_into_penalty_area')\n",
    "    miscontrols = get_dat(data_possession, 'miscontrols')\n",
    "    dispossesed = get_dat(data_possession, 'dispossessed')\n",
    "\n",
    "    #receiving \n",
    "    pass_received = get_dat(data_possession, 'passes_received')\n",
    "    prg_pass_received = get_dat(data_possession, 'progressive_passes_received')\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    #creating dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'Date': date,\n",
    "        'Day': day,\n",
    "        'Matchweek': matchweek,\n",
    "        'Venue': venue,\n",
    "        'Result': result,\n",
    "        'Team': team,\n",
    "        'Opponent': opponent, \n",
    "        'Start': start, \n",
    "        'Position': position,\n",
    "        'Minutes Played': mins, \n",
    "        'Goals': goals, \n",
    "        'Assists': assist, \n",
    "        'Penalties Scored': pen_goals, \n",
    "        'Penalties Attempted': pen_attempted, \n",
    "        'Shots': shots, \n",
    "        'Shots on Target': sot, \n",
    "        'Yellow Cards': yellow, \n",
    "        'Red Cards': red, \n",
    "        'Touches': touches, \n",
    "        'Tackles': tackles,\n",
    "        'Interceptions': interceptions, \n",
    "        'Blocks': blocks, \n",
    "        'xG': xg,\n",
    "        'npxG': npxg,\n",
    "        'xAG': xag, \n",
    "        'Shot Creating Actions': sca, \n",
    "        'Goal Creating Actions': gca, \n",
    "        'Passes Completed': passes_completed, \n",
    "        'Passes Attempted': passes_attempted, \n",
    "        'Progressive Passes': prg_passes,\n",
    "        'Carries': carries, \n",
    "        'Progressive Carries': prg_carries, \n",
    "        'Take-ons Attempted': takeon_att, \n",
    "        'Successful Take-ons': takeon_suc,\n",
    "        \n",
    "        'Passing Distance': pass_distance, \n",
    "        'Progressive Passing Distance': prg_pass_distance,\n",
    "        'Short Passes Completed' : short_pass_completed,\n",
    "        'Short Passes Attempted': short_pass_attempted,\n",
    "        'Medium Passes Completed': med_pass_completed,\n",
    "        'Medium Passes Attempted': med_pass_attempted,\n",
    "        'Long Passes Completed': long_pass_completed,\n",
    "        'Long Passes Attempted': long_pass_attempted,\n",
    "        'Expected Assists': xa,\n",
    "        'Key Passes': keypass,\n",
    "        'Passes into Final Third': finalthird_pass,\n",
    "        'Passes into Penalty Area': penaltyarea_pass,\n",
    "        'Crosses into Penalty Area': penaltyarea_cross,\n",
    "    \n",
    "        'Live Pass': live_pass,\n",
    "        'Dead Pass': dead_pass,\n",
    "        'Free Kick Pass': freekick_pass,\n",
    "        'Through Balls': through_balls,\n",
    "        'Switches': switches,\n",
    "        'Crosses': crosses,\n",
    "        'Throw Ins Taken': throwin,\n",
    "        'Corners Taken': corners,\n",
    "        'Passes Offside': offside_pass,\n",
    "    \n",
    "        'Live SCA': live_sca,\n",
    "        'Deadball SCA': deadball_sca,\n",
    "        'Take-on SCA': takeons_sca,\n",
    "        'Shot SCA': shots_sca,\n",
    "        'Foul SCA': fouls_sca,\n",
    "        'Defense SCA': defense_sca,\n",
    "    \n",
    "        'Live GCA': live_gca,\n",
    "        'Deadball GCA': deadball_gca,\n",
    "        'Take-on GCA': takeons_gca,\n",
    "        'Shot GCA': shots_gca,\n",
    "        'Foul GCA': fouls_gca,\n",
    "        'Defense GCA': defense_gca,\n",
    "    \n",
    "        'Tackles Won': tackles_won,\n",
    "        'Defensive Third Tackles': tackles_def,\n",
    "        'Middle Third Tackles': tackles_mid,\n",
    "        'Attacking Third Tackles': tackles_att,\n",
    "        'Dribblers Tackled': dribblers_tackled,\n",
    "        'Dribblers Tackled Attempts': dribbles_challenged,\n",
    "        'Challenges Lost': challenges_lost,\n",
    "        'Shots Blocked': shots_blocked,\n",
    "        'Passes Blocked': pass_blocked,\n",
    "        'Clearances': clearances,\n",
    "        'Defensive Errors': def_errors,\n",
    "    \n",
    "        'Defensive Penalty Area Touches': def_penarea_touches,\n",
    "        'Defensive Third Touches': def_third_touches,\n",
    "        'Middle Third Touches': mid_third_touches,\n",
    "        'Attacking Third Touches': att_third_touches,\n",
    "        'Penalty Area Touches': pen_area_touches,\n",
    "        'Carry Distance': carry_distance,\n",
    "        'Progressive Carry Distance': prg_carry_distance,\n",
    "        'Final Third Carries': final_third_carries,\n",
    "        'Carries into Penalty Area': pen_area_carries,\n",
    "        'Miscontrols': miscontrols,\n",
    "        'Dispossessed': dispossesed,\n",
    "        'Passes Received': pass_received,\n",
    "        'Progressive Passes Received': prg_pass_received\n",
    "    })\n",
    "    \n",
    "    #modifying data types\n",
    "    df = df.astype({\n",
    "        'Date': 'datetime64[ns]',\n",
    "        'Day': 'object',\n",
    "        'Matchweek': 'int64',\n",
    "        'Venue': 'object',\n",
    "        'Result': 'object',\n",
    "        'Team': 'object',\n",
    "        'Opponent': 'object', \n",
    "        'Start': 'object', \n",
    "        'Position': 'object',\n",
    "        'Minutes Played': 'int64', \n",
    "        'Goals': 'int64', \n",
    "        'Assists': 'int64', \n",
    "        'Penalties Scored': 'int64', \n",
    "        'Penalties Attempted': 'int64', \n",
    "        'Shots': 'int64', \n",
    "        'Shots on Target': 'int64', \n",
    "        'Yellow Cards': 'int64', \n",
    "        'Red Cards': 'int64', \n",
    "        'Touches': 'int64', \n",
    "        'Tackles': 'int64',\n",
    "        'Interceptions': 'int64', \n",
    "        'Blocks': 'int64', \n",
    "        'xG': 'float64',\n",
    "        'npxG': 'float64',\n",
    "        'xAG': 'float64', \n",
    "        'Shot Creating Actions': 'int64', \n",
    "        'Goal Creating Actions': 'int64', \n",
    "        'Passes Completed': 'int64', \n",
    "        'Passes Attempted': 'int64', \n",
    "        'Progressive Passes': 'int64',\n",
    "        'Carries': 'int64', \n",
    "        'Progressive Carries': 'int64', \n",
    "        'Take-ons Attempted': 'int64', \n",
    "        'Successful Take-ons': 'int64',\n",
    "        \n",
    "        'Short Passes Completed' : 'int64',\n",
    "        'Short Passes Attempted': 'int64',\n",
    "        'Medium Passes Completed': 'int64',\n",
    "        'Medium Passes Attempted': 'int64',\n",
    "        'Long Passes Completed': 'int64',\n",
    "        'Long Passes Attempted': 'int64',\n",
    "        'Expected Assists': 'float64',\n",
    "        'Key Passes': 'int64',\n",
    "        'Passes into Final Third': 'int64',\n",
    "        'Passes into Penalty Area': 'int64',\n",
    "        'Crosses into Penalty Area': 'int64',\n",
    "    \n",
    "        'Live Pass': 'int64',\n",
    "        'Dead Pass': 'int64',\n",
    "        'Free Kick Pass': 'int64',\n",
    "        'Through Balls': 'int64',\n",
    "        'Switches': 'int64',\n",
    "        'Crosses': 'int64',\n",
    "        'Throw Ins Taken': 'int64',\n",
    "        'Corners Taken': 'int64',\n",
    "        'Passes Offside': 'int64',\n",
    "    \n",
    "        'Live SCA': 'int64',\n",
    "        'Deadball SCA': 'int64',\n",
    "        'Take-on SCA': 'int64',\n",
    "        'Shot SCA': 'int64',\n",
    "        'Foul SCA': 'int64',\n",
    "        'Defense SCA': 'int64',\n",
    "    \n",
    "        'Live GCA': 'int64',\n",
    "        'Deadball GCA': 'int64',\n",
    "        'Take-on GCA': 'int64',\n",
    "        'Shot GCA': 'int64',\n",
    "        'Foul GCA': 'int64',\n",
    "        'Defense GCA': 'int64',\n",
    "    \n",
    "        'Tackles Won': 'int64',\n",
    "        'Defensive Third Tackles': 'int64',\n",
    "        'Middle Third Tackles': 'int64',\n",
    "        'Attacking Third Tackles': 'int64',\n",
    "        'Dribblers Tackled': 'int64',\n",
    "        'Dribblers Tackled Attempts': 'int64',\n",
    "        'Challenges Lost': 'int64',\n",
    "        'Shots Blocked': 'int64',\n",
    "        'Passes Blocked': 'int64',\n",
    "        'Clearances': 'int64',\n",
    "        'Defensive Errors': 'int64',\n",
    "    \n",
    "        'Defensive Penalty Area Touches': 'int64',\n",
    "        'Defensive Third Touches': 'int64',\n",
    "        'Middle Third Touches': 'int64',\n",
    "        'Attacking Third Touches': 'int64',\n",
    "        'Penalty Area Touches': 'int64',\n",
    "        'Carry Distance': 'float64',\n",
    "        'Progressive Carry Distance': 'float64',\n",
    "        'Final Third Carries': 'int64',\n",
    "        'Carries into Penalty Area': 'int64',\n",
    "        'Miscontrols': 'int64',\n",
    "        'Dispossessed': 'int64',\n",
    "        'Passes Received': 'int64',\n",
    "        'Progressive Passes Received': 'int64'\n",
    "    })\n",
    "    \n",
    "    #changing date column data type \n",
    "    df['Date'] = df['Date'].dt.date\n",
    "    \n",
    "    ###############################################################################\n",
    "    \n",
    "    #now we want to get the fpl data \n",
    "    start_year = year_range[:4] #getting the whole of the first year \n",
    "    end_year = year_range[-2:]\n",
    "    format_year = f'{start_year}-{end_year}'\n",
    "    directory = f'Fantasy-Premier-League/data/{format_year}/players'\n",
    "    files = os.listdir(directory)\n",
    "    csv_file = [f for f in files if fpl_name in f]\n",
    "    fpldf = pd.read_csv(os.path.join(directory, csv_file[0]) + '/gw.csv')\n",
    "\n",
    "    #some of the columns are duplicated (from the webscraped data), so we want to remove these \n",
    "    fpldf = fpldf.drop(['assists', 'expected_assists', 'expected_goal_involvements', 'expected_goals', 'fixture',\n",
    "                                          'goals_conceded', 'goals_scored', 'penalties_missed', 'penalties_saved', 'red_cards'\n",
    "                                          ,'team_a_score', 'team_h_score', 'was_home', 'yellow_cards', 'element', 'opponent_team', 'starts'\n",
    "                                          ,'expected_goals_conceded'], axis=1, \n",
    "                       errors = 'ignore')\n",
    "\n",
    "    #we now want to change the 'kickoff time' feature into a datetime object \n",
    "    fpldf['kickoff_time'] = pd.to_datetime(fpldf['kickoff_time'])\n",
    "\n",
    "    #creating new column, which is just the kickoff date \n",
    "    fpldf['kickoff_date'] = fpldf['kickoff_time'].dt.date\n",
    "    \n",
    "    finaldf = pd.merge(df, fpldf, left_on='Date', right_on='kickoff_date', how='inner')\n",
    "    \n",
    "    return(finaldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_premgames function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_premgames (code, player):\n",
    "    base_url = f'https://fbref.com/en/players/{code}/{player}'\n",
    "    html = requests.get(base_url).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    summary = soup.find('table', class_='stats_table sortable min_width')\n",
    "    table = summary.find('tbody')\n",
    "    \n",
    "    comp = table.find_all('td', attrs={'data-stat': 'comp_level'})\n",
    "    comp_text = [cell.get_text() for cell in comp]\n",
    "    games = table.find_all('td', attrs={'data-stat': 'games'})\n",
    "    games_text = [cell.get_text() for cell in games]\n",
    "    season = table.find_all('th', attrs={'data-stat': 'year_id'})\n",
    "    season_text  = [cell.get_text() for cell in season]\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Season': season_text,\n",
    "        'Competition': comp_text, \n",
    "        'Games Played': games_text\n",
    "    })\n",
    "\n",
    "    season_list = ('2023-2024', '2022-2023', '2021-2022', '2020-2021', '2019-2020', '2018-2019', '2017-2018')\n",
    "    total_games = df[(df['Competition'] == '1. Premier League') & (df['Season'].isin(season_list))]['Games Played']\n",
    "    total_games = pd.to_numeric(total_games)\n",
    "    prem_games = total_games.sum()\n",
    "    return(prem_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code specifies the location to place the .csv file into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_folder = (\"Player_Data\")\n",
    "os.makedirs(nest_folder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we actually use the functions above to get the necessary data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diogo Jota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_2324_finaldf = get_data('178ae8f8', '2023-2024', 'Diogo-Jota',  \"Diogo_Teixeira da Silva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_2223_finaldf = get_data('178ae8f8', '2022-2023', 'Diogo-Jota',  \"Diogo_Teixeira da Silva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_2122_finaldf = get_data('178ae8f8', '2021-2022', 'Diogo-Jota',  \"Diogo_Teixeira da Silva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_2021_finaldf = get_data('178ae8f8', '2020-2021', 'Diogo-Jota',  \"Diogo_Teixeira da Silva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_1920_finaldf = get_data('178ae8f8', '2019-2020', 'Diogo-Jota',  \"Diogo_Teixeira da Silva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_1819_finaldf = get_data('178ae8f8', '2018-2019', 'Diogo-Jota',  \"Diogo_Teixeira da Silva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jota_finaldat = pd.concat([jota_1819_finaldf, jota_1920_finaldf, jota_2021_finaldf, jota_2122_finaldf\n",
    "                            , jota_2223_finaldf, jota_2324_finaldf], join = 'inner', ignore_index = True)\n",
    "jota_finaldat.to_csv(os.path.join(nest_folder, \"jota_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luis Diaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaz_2324_finaldf = get_data('4a1a9578', '2023-2024', 'Luis-Diaz',  \"Luis_Díaz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaz_2223_finaldf = get_data('4a1a9578', '2022-2023', 'Luis-Diaz',  \"Luis_Díaz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaz_2122_finaldf = get_data('4a1a9578', '2021-2022', 'Luis-Diaz',  \"Luis_Díaz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaz_finaldat = pd.concat([diaz_2122_finaldf, diaz_2223_finaldf, diaz_2324_finaldf], join = 'inner', ignore_index = True)\n",
    "diaz_finaldat.to_csv(os.path.join(nest_folder, \"diaz_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cody Gakpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gakpo_2324_finaldf = get_data('1971591f', '2023-2024', 'Cody-Gakpo',  \"Cody_Gakpo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gakpo_2223_finaldf = get_data('1971591f', '2022-2023', 'Cody-Gakpo',  \"Cody_Gakpo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gakpo_finaldat = pd.concat([gakpo_2223_finaldf, gakpo_2324_finaldf], join = 'inner', ignore_index = True)\n",
    "gakpo_finaldat.to_csv(os.path.join(nest_folder, \"gakpo_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darwin Nunez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_2324_finaldf = get_data('4d77b365', '2023-2024', 'Darwin-Nunez',  \"Darwin_Núñez Ribeiro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_2223_finaldf = get_data('4d77b365', '2022-2023', 'Darwin-Nunez',  \"Darwin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_finaldat = pd.concat([darwin_2223_finaldf, darwin_2324_finaldf], join = 'inner', ignore_index = True)\n",
    "darwin_finaldat.to_csv(os.path.join(nest_folder, \"darwin_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Function\n",
    "This new function compile_dat allows us to get all of the data for a single player in one function, instead of having to do it one by one as can be seen above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_dat (code, player, fpl_name, checkgames):\n",
    "    #these are the seasons for which we have fpl data \n",
    "    year_list = ('2023-24', '2022-23', '2021-22', '2020-21', '2019-20', '2018-19', '2017-18')\n",
    "    \n",
    "    #active_years is a list that will store the seasons that a given player was active. The for loop will check to see which years a player was active\n",
    "    #in the prem, and will append this year to the list\n",
    "    active_years = []\n",
    "    for year in year_list: \n",
    "        directory = f'Fantasy-Premier-League/data/{year}/players'\n",
    "        files = os.listdir(directory)\n",
    "        csv_file = [f for f in files if fpl_name in f]\n",
    "        if csv_file:\n",
    "            update_year = year[:5] + '20' + year[5:]\n",
    "            active_years.append(update_year)\n",
    "    \n",
    "    #create an empty dictionary to store all of the dataframes \n",
    "    dataframes = {}\n",
    "    \n",
    "    #for each season a player was active, the get_data function from above is uesd to add the data for that season to the dataframes dictionary\n",
    "    for year in active_years: \n",
    "        dataframes[year] = get_data_final(code, year, player, fpl_name)\n",
    "        #1 minute pause in between each iteration, to ensure that we don't get banned from FBref\n",
    "        time.sleep(60)\n",
    "    \n",
    "    #concatenate all of the dataframes, and return one final concatenated dataframe\n",
    "    finaldf = pd.concat(dataframes.values(), join = \"inner\", ignore_index = True)\n",
    "    \n",
    "    if checkgames:\n",
    "        games_played = get_premgames(code, player)\n",
    "        if games_played == finaldf.shape[0]:\n",
    "            return(finaldf)\n",
    "        else:\n",
    "            return(print('The number of Premier League games played by ' + player + '(' + str(games_played) +  ') does not match the number of rows in the dataframe ('+ str(finaldf.shape[0]) + ')'))\n",
    "    else: \n",
    "        return(finaldf)\n",
    "\n",
    "#note that the to_csv code is not included in this function, because there are certain players whose names were changed in between seasons \n",
    "#(e.g. Diogo Teixeira da Silva to Diogo Jota). In these cases, we need to use the compile function twice to get all of the data, before concatenating\n",
    "#and then finally exporting to csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arsenal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "saka_finaldat = compile_dat('bc7dc64d', 'Bukayo-Saka', 'Bukayo')\n",
    "saka_finaldat.to_csv(os.path.join(nest_folder, \"saka_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "havertz_finaldat = compile_dat('fed7cb61', 'Kai-Havertz', 'Kai_Havertz')\n",
    "havertz_finaldat.to_csv(os.path.join(nest_folder, \"havertz_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "jesus_finaldat = compile_dat('b66315ae', 'Gabriel-Jesus', 'de Jesus')\n",
    "jesus_finaldat.to_csv(os.path.join(nest_folder, \"jesus_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trossard_finaldat = compile_dat('38ceb24a', 'Leandro-Trossard', 'Leandro_Trossard')\n",
    "trossard_finaldat.to_csv(os.path.join(nest_folder, \"trossard_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "martinelli_finaldat = compile_dat('48a5a5d6', 'Gabriel-Martinelli', 'Martinelli')\n",
    "martinelli_finaldat.to_csv(os.path.join(nest_folder, \"martinelli_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "odegaard_finaldat = compile_dat('79300479', 'Martin-Odegaard', 'Ødegaard')\n",
    "odegaard_finaldat.to_csv(os.path.join(nest_folder, \"odegaard_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sterling_finaldat = compile_dat('b400bde0', 'Raheem-Sterling', 'Raheem_Sterling')\n",
    "sterling_finaldat.to_csv(os.path.join(nest_folder, \"sterling_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "jorginho_finaldat = compile_dat('45db685d', 'Jorginho', 'Jorge Luiz_Frello', checkgames = True)\n",
    "if isinstance(jorginho_finaldat, pd.DataFrame):\n",
    "    jorginho_finaldat.to_csv(os.path.join(nest_folder, \"jorginho_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_finaldat = compile_dat('1c7012b8', 'Declan-Rice', 'Declan_Rice', checkgames = True)\n",
    "if isinstance(rice_finaldat, pd.DataFrame):\n",
    "    rice_finaldat.to_csv(os.path.join(nest_folder, \"rice_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "partey_finaldat = compile_dat('529f49ab', 'Thomas-Partey', 'Thomas_Partey', checkgames = True)\n",
    "if isinstance(partey_finaldat, pd.DataFrame):\n",
    "    partey_finaldat.to_csv(os.path.join(nest_folder, \"partey_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aston Villa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "duran_finaldat = compile_dat('414184f7', 'Jhon-Duran', 'Jhon', checkgames=True)\n",
    "duran_finaldat.to_csv(os.path.join(nest_folder, \"duran_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "watkins_finaldat = compile_dat('aed3a70f', 'Ollie-Watkins', 'Ollie_Watkins', checkgames=True)\n",
    "if isinstance(watkins_finaldat, pd.DataFrame):\n",
    "    watkins_finaldat.to_csv(os.path.join(nest_folder, \"watkins_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramsey_finaldat = compile_dat('1544f145', 'Jacob-Ramsey', 'Jacob_Ramsey', checkgames = True)\n",
    "if isinstance(ramsey_finaldat, pd.DataFrame):\n",
    "    ramsey_finaldat.to_csv(os.path.join(nest_folder, \"ramsey_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcginn_finaldat = compile_dat('90f91999', 'John-McGinn', 'John_McGinn', checkgames = False)\n",
    "if isinstance(mcginn_finaldat, pd.DataFrame):\n",
    "    mcginn_finaldat.to_csv(os.path.join(nest_folder, \"mcginn_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "bailey_finaldat = compile_dat('3a233281', 'Leon-Bailey', 'Leon_Bailey', checkgames = True)\n",
    "if isinstance(bailey_finaldat, pd.DataFrame):\n",
    "    bailey_finaldat.to_csv(os.path.join(nest_folder, \"bailey_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/bjx4hkg54x17symh1g3_3jf80000gq/T/ipykernel_60248/2405533476.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  finaldf = pd.concat(dataframes.values(), join = \"inner\", ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "buendia_finaldat = compile_dat('66b76d44', 'Emi-Buendia', 'Emiliano_Buen', checkgames = True)\n",
    "if isinstance(buendia_finaldat, pd.DataFrame):\n",
    "    buendia_finaldat.to_csv(os.path.join(nest_folder, \"buendia_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tielemans_finaldat = compile_dat('56f7a928', 'Youri-Tielemans', 'Youri_Tielemans', checkgames = True)\n",
    "if isinstance(tielemans_finaldat, pd.DataFrame):\n",
    "    tielemans_finaldat.to_csv(os.path.join(nest_folder, \"tielemans_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/bjx4hkg54x17symh1g3_3jf80000gq/T/ipykernel_60248/2561086557.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  finaldf = pd.concat(dataframes.values(), join = \"inner\", ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "barkley_finaldat = compile_dat('3a24769f', 'Ross-Barkley', 'Ross_Barkley', checkgames = False)\n",
    "if isinstance(barkley_finaldat, pd.DataFrame):\n",
    "    barkley_finaldat.to_csv(os.path.join(nest_folder, \"barkley_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "onana_finaldat = compile_dat('828657ff', 'Amadou-Onana', 'Amadou_Onana', checkgames = True)\n",
    "if isinstance(onana_finaldat, pd.DataFrame):\n",
    "    onana_finaldat.to_csv(os.path.join(nest_folder, \"onana_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rogers_finaldat = compile_dat('2e5915f1', 'Morgan-Rogers', 'Morgan_Rogers', checkgames = True)\n",
    "if isinstance(rogers_finaldat, pd.DataFrame):\n",
    "    rogers_finaldat.to_csv(os.path.join(nest_folder, \"rogers_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bournemouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "unal_finaldat = compile_dat('f8eca1b6', 'Enes-Unal', 'Enes', checkgames = True)\n",
    "if isinstance(unal_finaldat, pd.DataFrame):\n",
    "    unal_finaldat.to_csv(os.path.join(nest_folder, \"unal_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "semenyo_finaldat = compile_dat('efd2ec23', 'Antoine-Semenyo', 'Antoine_Semenyo', checkgames = True)\n",
    "if isinstance(semenyo_finaldat, pd.DataFrame):\n",
    "    semenyo_finaldat.to_csv(os.path.join(nest_folder, \"semenyo_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinisterra_finaldat = compile_dat('8e16dd48', 'Luis-Sinisterra', 'Luis_Sinisterra', checkgames = True)\n",
    "if isinstance(sinisterra_finaldat, pd.DataFrame):\n",
    "    sinisterra_finaldat.to_csv(os.path.join(nest_folder, \"sinisterra_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavernier_finaldat = compile_dat('5c0da4a4', 'Marcus-Tavernier', 'Marcus_Tavernier', checkgames = True)\n",
    "if isinstance(tavernier_finaldat, pd.DataFrame):\n",
    "    tavernier_finaldat.to_csv(os.path.join(nest_folder, \"tavernier_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cook_finaldat = compile_dat('2afc7272', 'Lewis-Cook', 'Lewis_Cook', checkgames = True)\n",
    "if isinstance(cook_finaldat, pd.DataFrame):\n",
    "    cook_finaldat.to_csv(os.path.join(nest_folder, \"cook_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "kluivert_finaldat = compile_dat('4c3a6744', 'Justin-Kluivert', 'Justin_Kluivert', checkgames = True)\n",
    "if isinstance(kluivert_finaldat, pd.DataFrame):\n",
    "    kluivert_finaldat.to_csv(os.path.join(nest_folder, \"kluivert_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dango_finaldat = compile_dat('2f9e4435', 'Dango-Ouattara', 'Dango_Ouattara', checkgames = True)\n",
    "if isinstance(dango_finaldat, pd.DataFrame):\n",
    "    dango_finaldat.to_csv(os.path.join(nest_folder, \"dango_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "christie_finaldat = compile_dat('26ce2263', 'Ryan-Christie', 'Ryan_Christie', checkgames = True)\n",
    "if isinstance(christie_finaldat, pd.DataFrame):\n",
    "    christie_finaldat.to_csv(os.path.join(nest_folder, \"christie_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "scott_finaldat = compile_dat('104d0bb8', 'Alex-Scott', 'Alex_Scott', checkgames = True)\n",
    "if isinstance(scott_finaldat, pd.DataFrame):\n",
    "    scott_finaldat.to_csv(os.path.join(nest_folder, \"scott_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "billing_finaldat = compile_dat('d328a254', 'Philip-Billing', 'Philip_Billing', checkgames = True)\n",
    "if isinstance(billing_finaldat, pd.DataFrame):\n",
    "    billing_finaldat.to_csv(os.path.join(nest_folder, \"billing_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "adams_finaldat = compile_dat('2b09d998', 'Tyler-Adams', 'Tyler_Adams', checkgames = True)\n",
    "if isinstance(adams_finaldat, pd.DataFrame):\n",
    "    adams_finaldat.to_csv(os.path.join(nest_folder, \"adams_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooks_finaldat = compile_dat('dc4cae05', 'David-Brooks', 'David_Brooks', checkgames = True)\n",
    "if isinstance(brooks_finaldat, pd.DataFrame):\n",
    "    brooks_finaldat.to_csv(os.path.join(nest_folder, \"brooks_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brentford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "toney_finaldat = compile_dat('e09f279b', 'Ivan-Toney', 'Ivan_Toney', checkgames = True)\n",
    "if isinstance(toney_finaldat, pd.DataFrame):\n",
    "    toney_finaldat.to_csv(os.path.join(nest_folder, \"toney_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "wissa_finaldat = compile_dat('2500cef9', 'Yoane-Wissa', 'Yoane_Wissa', checkgames = True)\n",
    "if isinstance(wissa_finaldat, pd.DataFrame):\n",
    "    wissa_finaldat.to_csv(os.path.join(nest_folder, \"wissa_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbeumo_finaldat = compile_dat('6afaebf2', 'Bryan-Mbeumo', 'Bryan_Mbeumo', checkgames = True)\n",
    "if isinstance(mbeumo_finaldat, pd.DataFrame):\n",
    "    mbeumo_finaldat.to_csv(os.path.join(nest_folder, \"mbeumo_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "jensen_finaldat = compile_dat('0f134faf', 'Mathias-Jensen', 'Mathias_Jensen', checkgames = True)\n",
    "if isinstance(jensen_finaldat, pd.DataFrame):\n",
    "    jensen_finaldat.to_csv(os.path.join(nest_folder, \"jensen_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "schade_finaldat = compile_dat('52afb588', 'Kevin-Schade', 'Kevin_Schade', checkgames = True)\n",
    "if isinstance(schade_finaldat, pd.DataFrame):\n",
    "    schade_finaldat.to_csv(os.path.join(nest_folder, \"schade_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "janelt_finaldat = compile_dat('8449d35e', 'Vitaly-Janelt', 'Vitaly_Janelt', checkgames = True)\n",
    "if isinstance(janelt_finaldat, pd.DataFrame):\n",
    "    janelt_finaldat.to_csv(os.path.join(nest_folder, \"janelt_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "damsgaard_finaldat = compile_dat('215f3907', 'Mikkel-Damsgaard', 'Mikkel_Damsgaard', checkgames = True)\n",
    "if isinstance(damsgaard_finaldat, pd.DataFrame):\n",
    "    damsgaard_finaldat.to_csv(os.path.join(nest_folder, \"damsgaard_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "norgaard_finaldat = compile_dat('df0a4c90', 'Christian-Norgaard', 'Christian_Nø', checkgames = True)\n",
    "if isinstance(norgaard_finaldat, pd.DataFrame):\n",
    "    norgaard_finaldat.to_csv(os.path.join(nest_folder, \"norgaard_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "lewispotter_finaldat = compile_dat('41f08ac8', 'Keane-Lewis-Potter', 'Keane_Lewis', checkgames = True)\n",
    "if isinstance(lewispotter_finaldat, pd.DataFrame):\n",
    "    lewispotter_finaldat.to_csv(os.path.join(nest_folder, \"lewispotter_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brighton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "welbeck_finaldat = compile_dat('ce5143da', 'Danny-Welbeck', 'Danny_Welbeck', checkgames = True)\n",
    "if isinstance(welbeck_finaldat, pd.DataFrame):\n",
    "    welbeck_finaldat.to_csv(os.path.join(nest_folder, \"welbeck_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpedro_finaldat = compile_dat('e8832875', 'Joao-Pedro', 'Junqueira', checkgames = True)\n",
    "if isinstance(jpedro_finaldat, pd.DataFrame):\n",
    "    jpedro_finaldat.to_csv(os.path.join(nest_folder, \"jpedro_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferguson_finaldat = compile_dat('4596da74', 'Evan-Ferguson', 'Evan_Ferguson', checkgames = True)\n",
    "if isinstance(ferguson_finaldat, pd.DataFrame):\n",
    "    ferguson_finaldat.to_csv(os.path.join(nest_folder, \"ferguson_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitoma_finaldat = compile_dat('74618572', 'Kaoru-Mitoma', 'Kaoru_Mitoma', checkgames = True)\n",
    "if isinstance(mitoma_finaldat, pd.DataFrame):\n",
    "    mitoma_finaldat.to_csv(os.path.join(nest_folder, \"mitoma_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "adingra_finaldat = compile_dat('4dcec659', 'Simon-Adingra', 'Simon_Adingra', checkgames = True)\n",
    "if isinstance(adingra_finaldat, pd.DataFrame):\n",
    "    adingra_finaldat.to_csv(os.path.join(nest_folder, \"adingra_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinshelwood_finaldat = compile_dat('e98211e7', 'Jack-Hinshelwood', 'Jack_Hinshelwood', checkgames = True)\n",
    "if isinstance(hinshelwood_finaldat, pd.DataFrame):\n",
    "    hinshelwood_finaldat.to_csv(os.path.join(nest_folder, \"hinshelwood_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "milner_finaldat = compile_dat('2f90f6b8', 'James-Milner', 'James_Milner', checkgames = True)\n",
    "if isinstance(milner_finaldat, pd.DataFrame):\n",
    "    milner_finaldat.to_csv(os.path.join(nest_folder, \"milner_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "enciso_finaldat = compile_dat('9cfbad36', 'Julio-Enciso', 'Julio_Enciso', checkgames = True)\n",
    "if isinstance(enciso_finaldat, pd.DataFrame):\n",
    "    enciso_finaldat.to_csv(os.path.join(nest_folder, \"enciso_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "march_latedat = compile_dat('bb5fbd2b', 'Solly-March', 'Solly_March', checkgames = False)\n",
    "march_earlydat = compile_dat('bb5fbd2b', 'Solly-March', 'Solomon_March', checkgames = False)\n",
    "march_finaldat = pd.concat([march_latedat, march_earlydat], join = \"inner\", ignore_index = True)\n",
    "if isinstance(march_finaldat, pd.DataFrame):\n",
    "    march_finaldat.to_csv(os.path.join(nest_folder, \"march_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chelsea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "jackson_finaldat = compile_dat('9c36ed83', 'Nicolas-Jackson', 'Nicolas_Jackson', checkgames = True)\n",
    "if isinstance(jackson_finaldat, pd.DataFrame):\n",
    "    jackson_finaldat.to_csv(os.path.join(nest_folder, \"jackson_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "palmer_finaldat = compile_dat('dc7f8a28', 'Cole-Palmer', 'Cole_Palmer', checkgames = True)\n",
    "if isinstance(palmer_finaldat, pd.DataFrame):\n",
    "    palmer_finaldat.to_csv(os.path.join(nest_folder, \"palmer_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "madueke_finaldat = compile_dat('bf34eebd', 'Noni-Madueke', 'Noni_Madueke', checkgames = True)\n",
    "if isinstance(madueke_finaldat, pd.DataFrame):\n",
    "    madueke_finaldat.to_csv(os.path.join(nest_folder, \"madueke_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "felix_finaldat = compile_dat('8aafd64f', 'Joao-Felix', 'Sequeira', checkgames = True)\n",
    "if isinstance(felix_finaldat, pd.DataFrame):\n",
    "    felix_finaldat.to_csv(os.path.join(nest_folder, \"felix_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzo_finaldat = compile_dat('5ff4ab71', 'Enzo-Fernandez', 'Enzo_Fern', checkgames = True)\n",
    "if isinstance(enzo_finaldat, pd.DataFrame):\n",
    "    enzo_finaldat.to_csv(os.path.join(nest_folder, \"enzo_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "caicedo_finaldat = compile_dat('16264a81', 'Moises-Caicedo', 'Caicedo', checkgames = True)\n",
    "if isinstance(caicedo_finaldat, pd.DataFrame):\n",
    "    caicedo_finaldat.to_csv(os.path.join(nest_folder, \"caicedo_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "neto_finaldat = compile_dat('7ba2eaa9', 'Pedro-Neto', 'Pedro_Lomba', checkgames = True)\n",
    "if isinstance(neto_finaldat, pd.DataFrame):\n",
    "    neto_finaldat.to_csv(os.path.join(nest_folder, \"neto_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "dewsburyhall_finaldat = compile_dat('5c74c0f5', 'Kiernan-Dewsbury-Hall', 'Kiernan_Dewsbury', checkgames = True)\n",
    "if isinstance(dewsburyhall_finaldat, pd.DataFrame):\n",
    "    dewsburyhall_finaldat.to_csv(os.path.join(nest_folder, \"dewsburyhall_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "mudryk_finaldat = compile_dat('049a888d', 'Mykhailo-Mudryk', 'Mykhailo_Mudryk', checkgames = False)\n",
    "if isinstance(mudryk_finaldat, pd.DataFrame):\n",
    "    mudryk_finaldat.to_csv(os.path.join(nest_folder, \"mudryk_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crystal Palace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nketiah_latedat = compile_dat('a53649b7', 'Eddie-Nketiah', 'Eddie_Nketiah', checkgames = False)\n",
    "nketiah_earlydat = compile_dat('a53649b7', 'Eddie-Nketiah', 'Edward_Nketiah', checkgames = False)\n",
    "nketiah_finaldat = pd.concat([nketiah_latedat, nketiah_earlydat], join = \"inner\", ignore_index = True)\n",
    "if isinstance(nketiah_finaldat, pd.DataFrame):\n",
    "    nketiah_finaldat.to_csv(os.path.join(nest_folder, \"nketiah_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "mateta_finaldat = compile_dat('50e6dc35', 'Jean-Philippe-Mateta', 'Jean-Philippe_Mateta', checkgames = True)\n",
    "if isinstance(mateta_finaldat, pd.DataFrame):\n",
    "    mateta_finaldat.to_csv(os.path.join(nest_folder, \"mateta_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "eze_finaldat = compile_dat('ae4fc6a4', 'Eberechi-Eze', 'Eberechi_Eze', checkgames = True)\n",
    "if isinstance(eze_finaldat, pd.DataFrame):\n",
    "    eze_finaldat.to_csv(os.path.join(nest_folder, \"eze_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "wharton_finaldat = compile_dat('4b542852', 'Adam-Wharton', 'Adam_Wharton', checkgames = True)\n",
    "if isinstance(wharton_finaldat, pd.DataFrame):\n",
    "    wharton_finaldat.to_csv(os.path.join(nest_folder, \"wharton_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheick_finaldat = compile_dat('ce4f40c7', 'Cheick-Doucoure', 'Cheick_Doucou', checkgames = True)\n",
    "if isinstance(cheick_finaldat, pd.DataFrame):\n",
    "    cheick_finaldat.to_csv(os.path.join(nest_folder, \"cheick_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "lerma_finaldat = compile_dat('9b5ce51a', 'Jefferson-Lerma', 'Jefferson_Lerma', checkgames = True)\n",
    "if isinstance(lerma_finaldat, pd.DataFrame):\n",
    "    lerma_finaldat.to_csv(os.path.join(nest_folder, \"lerma_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Premier League games played by Ismaila-Sarr(50) does not match the number of rows in the dataframe (22)\n"
     ]
    }
   ],
   "source": [
    "ismailasarr_finaldat = compile_dat('bfdb33aa', 'Ismaila-Sarr', 'Ismaila_Sarr', checkgames = True)\n",
    "if isinstance(ismailasarr_finaldat, pd.DataFrame):\n",
    "    ismailasarr_finaldat.to_csv(os.path.join(nest_folder, \"ismailasarr_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "hughes_finaldat = compile_dat('a0666d3e', 'Will-Hughes', 'Will_Hughes', checkgames = True)\n",
    "if isinstance(hughes_finaldat, pd.DataFrame):\n",
    "    hughes_finaldat.to_csv(os.path.join(nest_folder, \"hughes_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "schlupp_finaldat = compile_dat('3312f911', 'Jeffrey-Schlupp', 'Jeffrey_Schlupp', checkgames = True)\n",
    "if isinstance(schlupp_finaldat, pd.DataFrame):\n",
    "    schlupp_finaldat.to_csv(os.path.join(nest_folder, \"schlupp_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "calvertlewin_finaldat = compile_dat('59e6e5bf', 'Dominic-Calvert-Lewin', 'Dominic_Calvert', checkgames = True)\n",
    "if isinstance(calvertlewin_finaldat, pd.DataFrame):\n",
    "    calvertlewin_finaldat.to_csv(os.path.join(nest_folder, \"calvertlewin_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "beto_finaldat = compile_dat('ed5c0319', 'Beto', 'Norberto Bercique', checkgames = True)\n",
    "if isinstance(beto_finaldat, pd.DataFrame):\n",
    "    beto_finaldat.to_csv(os.path.join(nest_folder, \"beto_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "broja_finaldat = compile_dat('97220da2', 'Armando-Broja', 'Armando_Broja', checkgames = True)\n",
    "if isinstance(broja_finaldat, pd.DataFrame):\n",
    "    broja_finaldat.to_csv(os.path.join(nest_folder, \"broja_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Premier League games played by Dwight-McNeil(204) does not match the number of rows in the dataframe (205)\n"
     ]
    }
   ],
   "source": [
    "mcneil_finaldat = compile_dat('fc15fb84', 'Dwight-McNeil', 'Dwight_McNeil', checkgames = True)\n",
    "if isinstance(mcneil_finaldat, pd.DataFrame):\n",
    "    mcneil_finaldat.to_csv(os.path.join(nest_folder, \"mcneil_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/bjx4hkg54x17symh1g3_3jf80000gq/T/ipykernel_60248/3417702198.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  finaldf = pd.concat(dataframes.values(), join = \"inner\", ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "gueye_finaldat = compile_dat('72c812f3', 'Idrissa-Gana-Gueye', 'Idrissa_Gueye', checkgames = True)\n",
    "if isinstance(gueye_finaldat, pd.DataFrame):\n",
    "    gueye_finaldat.to_csv(os.path.join(nest_folder, \"gueye_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "harrison_finaldat = compile_dat('aa849a12', 'Jack-Harrison', 'Jack_Harrison', checkgames = True)\n",
    "if isinstance(harrison_finaldat, pd.DataFrame):\n",
    "    harrison_finaldat.to_csv(os.path.join(nest_folder, \"harrison_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "doucoure_finaldat = compile_dat('02b29014', 'Abdoulaye-Doucoure', 'Abdoulaye_Douco', checkgames = True)\n",
    "if isinstance(doucoure_finaldat, pd.DataFrame):\n",
    "    doucoure_finaldat.to_csv(os.path.join(nest_folder, \"doucoure_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/bjx4hkg54x17symh1g3_3jf80000gq/T/ipykernel_60248/3417702198.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  finaldf = pd.concat(dataframes.values(), join = \"inner\", ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "garner_finaldat = compile_dat('4e015693', 'James-Garner', 'James_Garner', checkgames = True)\n",
    "if isinstance(garner_finaldat, pd.DataFrame):\n",
    "    garner_finaldat.to_csv(os.path.join(nest_folder, \"garner_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fulham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "muniz_finaldat = compile_dat('a755db8c', 'Rodrigo-Muniz', 'Rodrigo_Muniz', checkgames = True)\n",
    "if isinstance(muniz_finaldat, pd.DataFrame):\n",
    "    muniz_finaldat.to_csv(os.path.join(nest_folder, \"muniz_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "raul_earlydat = compile_dat('b561db50', 'Raul-Jimenez', 'Raúl_Jiménez', checkgames = False)\n",
    "raul_latedat = compile_dat('b561db50', 'Raul-Jimenez', 'Jiménez', checkgames = False)\n",
    "raul_finaldat = pd.concat([raul_latedat, raul_earlydat], join = \"inner\", ignore_index = True)\n",
    "if isinstance(raul_finaldat, pd.DataFrame):\n",
    "    raul_finaldat.to_csv(os.path.join(nest_folder, \"raul_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "carlosvini_finaldat = compile_dat('8b529245', 'Carlos-Vinicius', 'Carlos Vin', checkgames = True)\n",
    "if isinstance(carlosvini_finaldat, pd.DataFrame):\n",
    "    carlosvini_finaldat.to_csv(os.path.join(nest_folder, \"carlosvini_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Premier League games played by Adama-Traore(174) does not match the number of rows in the dataframe (163)\n"
     ]
    }
   ],
   "source": [
    "adama_finaldat = compile_dat('9a28eba4', 'Adama-Traore', 'Adama', checkgames = True)\n",
    "if isinstance(adama_finaldat, pd.DataFrame):\n",
    "    adama_finaldat.to_csv(os.path.join(nest_folder, \"adama_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "smithrowe_finaldat = compile_dat('17695062', 'Emile-Smith-Rowe', 'Emile_Smith', checkgames = True)\n",
    "if isinstance(smithrowe_finaldat, pd.DataFrame):\n",
    "    smithrowe_finaldat.to_csv(os.path.join(nest_folder, \"smithrowe_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwobi_finaldat = compile_dat('6ca5ec4b', 'Alex-Iwobi', 'Alex_Iwobi', checkgames = True)\n",
    "if isinstance(iwobi_finaldat, pd.DataFrame):\n",
    "    iwobi_finaldat.to_csv(os.path.join(nest_folder, \"iwobi_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/bjx4hkg54x17symh1g3_3jf80000gq/T/ipykernel_60248/3417702198.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  finaldf = pd.concat(dataframes.values(), join = \"inner\", ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "andreas_earlydat = compile_dat('6639e500', 'Andreas-Pereira', 'Andreas_Pereira', checkgames = False)\n",
    "andreas_latedat = compile_dat('6639e500', 'Andreas-Pereira', 'Hoelgebaum', checkgames = False)\n",
    "andreas_finaldat = pd.concat([andreas_latedat, andreas_earlydat], join = \"inner\", ignore_index = True)\n",
    "if isinstance(andreas_finaldat, pd.DataFrame):\n",
    "    andreas_finaldat.to_csv(os.path.join(nest_folder, \"andreas_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "lukic_finaldat = compile_dat('c6e8cf1f', 'Sasa-Lukic', 'Lukic', checkgames = True)\n",
    "if isinstance(lukic_finaldat, pd.DataFrame):\n",
    "    lukic_finaldat.to_csv(os.path.join(nest_folder, \"lukic_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "reed_finaldat = compile_dat('803ae100', 'Harrison-Reed', 'Harrison_Reed', checkgames = True)\n",
    "if isinstance(reed_finaldat, pd.DataFrame):\n",
    "    reed_finaldat.to_csv(os.path.join(nest_folder, \"reed_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/bjx4hkg54x17symh1g3_3jf80000gq/T/ipykernel_60248/3417702198.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  finaldf = pd.concat(dataframes.values(), join = \"inner\", ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "wilson_finaldat = compile_dat('c6dc9ecd', 'Harry-Wilson', 'Harry_Wilson', checkgames = True)\n",
    "if isinstance(wilson_finaldat, pd.DataFrame):\n",
    "    wilson_finaldat.to_csv(os.path.join(nest_folder, \"wilson_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/bjx4hkg54x17symh1g3_3jf80000gq/T/ipykernel_60248/3417702198.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  finaldf = pd.concat(dataframes.values(), join = \"inner\", ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "nelson_finaldat = compile_dat('c5bdb6e3', 'Reiss-Nelson', 'Reiss_Nelson', checkgames = True)\n",
    "if isinstance(nelson_finaldat, pd.DataFrame):\n",
    "    nelson_finaldat.to_csv(os.path.join(nest_folder, \"nelson_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/bjx4hkg54x17symh1g3_3jf80000gq/T/ipykernel_60248/3417702198.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  finaldf = pd.concat(dataframes.values(), join = \"inner\", ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Premier League games played by Tom-Cairney(108) does not match the number of rows in the dataframe (67)\n"
     ]
    }
   ],
   "source": [
    "cairney_finaldat = compile_dat('a8748947', 'Tom-Cairney', 'Tom_Cairney', checkgames = True)\n",
    "if isinstance(cairney_finaldat, pd.DataFrame):\n",
    "    cairney_finaldat.to_csv(os.path.join(nest_folder, \"cairney_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[180], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m berge_finaldat \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_dat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md0b6129f\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSander-Berge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSander_Berge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckgames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(berge_finaldat, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m      3\u001b[0m     berge_finaldat\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(nest_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mberge_finaldat.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[136], line 29\u001b[0m, in \u001b[0;36mcompile_dat\u001b[0;34m(code, player, fpl_name, checkgames)\u001b[0m\n\u001b[1;32m     26\u001b[0m finaldf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dataframes\u001b[38;5;241m.\u001b[39mvalues(), join \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m, ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkgames:\n\u001b[0;32m---> 29\u001b[0m     games_played \u001b[38;5;241m=\u001b[39m \u001b[43mget_premgames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m games_played \u001b[38;5;241m==\u001b[39m finaldf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m(finaldf)\n",
      "Cell \u001b[0;32mIn[96], line 6\u001b[0m, in \u001b[0;36mget_premgames\u001b[0;34m(code, player)\u001b[0m\n\u001b[1;32m      4\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m summary \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstats_table sortable min_width\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m comp \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata-stat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomp_level\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      9\u001b[0m comp_text \u001b[38;5;241m=\u001b[39m [cell\u001b[38;5;241m.\u001b[39mget_text() \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m comp]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "berge_finaldat = compile_dat('d0b6129f', 'Sander-Berge', 'Sander_Berge', checkgames = True)\n",
    "if isinstance(berge_finaldat, pd.DataFrame):\n",
    "    berge_finaldat.to_csv(os.path.join(nest_folder, \"berge_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leicester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vardy_finaldat = compile_dat('45963054', 'Jamie-Vardy', 'Jamie_Vardy', checkgames = True)\n",
    "if isinstance(vardy_finaldat, pd.DataFrame):\n",
    "    vardy_finaldat.to_csv(os.path.join(nest_folder, \"vardy_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edouard_finaldat = compile_dat('0562b7f1', 'Odsonne-Edouard', 'Odsonne_', checkgames = True)\n",
    "if isinstance(edouard_finaldat, pd.DataFrame):\n",
    "    edouard_finaldat.to_csv(os.path.join(nest_folder, \"edouard_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daka_finaldat = compile_dat('ca45605e', 'Patson-Daka', 'Patson_Daka', checkgames = True)\n",
    "if isinstance(daka_finaldat, pd.DataFrame):\n",
    "    daka_finaldat.to_csv(os.path.join(nest_folder, \"daka_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buonanotte_finaldat = compile_dat('468a7a91', 'Facundo-Buonanotte', 'Facundo_B', checkgames = True)\n",
    "if isinstance(buonanotte_finaldat, pd.DataFrame):\n",
    "    buonanotte_finaldat.to_csv(os.path.join(nest_folder, \"buonanotte_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndidi_finaldat = compile_dat('6b47c5db', 'Wilfred-Ndidi', checkgames = True)\n",
    "if isinstance(ndidi_finaldat, pd.DataFrame):\n",
    "    ndidi_finaldat.to_csv(os.path.join(nest_folder, \"ndidi_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decordovareid_earlydat = compile_dat('0f7533cd', 'Bobby-Reid', 'Bobby_Reid', checkgames = False)\n",
    "decordovareid_latedat = compile_dat('0f7533cd', 'Bobby-Reid', 'Bobby_De', checkgames = False)\n",
    "decordovareid_finaldat = pd.concat([decordovareid_latedat, decordovareid_earlydat], join = \"inner\", ignore_index = True)\n",
    "if isinstance(decordovareid_finaldat, pd.DataFrame):\n",
    "    decordovareid_finaldat.to_csv(os.path.join(nest_folder, \"decordovareid_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winks_finaldat = compile_dat('2f7acede', 'Harry-Winks', 'Harry_Winks', checkgames = True)\n",
    "if isinstance(winks_finaldat, pd.DataFrame):\n",
    "    winks_finaldat.to_csv(os.path.join(nest_folder, \"winks_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jayew_finaldat = compile_dat('da052c14', 'Jordan-Ayew', 'Jordan_Ayew', checkgames = True)\n",
    "if isinstance(jayew_finaldat, pd.DataFrame):\n",
    "    jayew_finaldat.to_csv(os.path.join(nest_folder, \"jayew_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipp_finaldat = compile_dat('6250083a', 'Oliver-Skipp', 'Oliver_Skipp', checkgames = True)\n",
    "if isinstance(skipp_finaldat, pd.DataFrame):\n",
    "    skipp_finaldat.to_csv(os.path.join(nest_folder, \"skipp_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soumare_finaldat = compile_dat('ae59b359', 'Boubakary-Soumare', 'Boubakary_Sou', checkgames = True)\n",
    "if isinstance(soumare_finaldat, pd.DataFrame):\n",
    "    soumare_finaldat.to_csv(os.path.join(nest_folder, \"soumare_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choudhury_finaldat = compile_dat('7d2d3329', 'Hamza-Choudhury', 'Hamza_Choudhury', checkgames = True)\n",
    "if isinstance(choudhury_finaldat, pd.DataFrame):\n",
    "    choudhury_finaldat.to_csv(os.path.join(nest_folder, \"choudhury_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liverpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szoboszlai_finaldat = compile_dat('934e1968', 'Dominik-Szoboszlai', 'Dominik_Szoboszlai', checkgames = True)\n",
    "if isinstance(szoboszlai_finaldat, pd.DataFrame):\n",
    "    szoboszlai_finaldat.to_csv(os.path.join(nest_folder, \"szoboszlai_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macallister_finaldat = compile_dat('83d074ff', 'Alexis-Mac-Allister', 'Alexis_Mac', checkgames = True)\n",
    "if isinstance(macallister_finaldat, pd.DataFrame):\n",
    "    macallister_finaldat.to_csv(os.path.join(nest_folder, \"macallister_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravenberch_finaldat = compile_dat('b8e740fb', 'Ryan-Gravenberch', 'Ryan_Gravenberch', checkgames = True)\n",
    "if isinstance(gravenberch_finaldat, pd.DataFrame):\n",
    "    gravenberch_finaldat.to_csv(os.path.join(nest_folder, \"gravenberch_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elliott_finaldat = compile_dat('b9e1436c', 'Harvey-Elliott', 'Harvey_Elliott', checkgames = True)\n",
    "if isinstance(elliott_finaldat, pd.DataFrame):\n",
    "    elliott_finaldat.to_csv(os.path.join(nest_folder, \"elliott_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curtis_finaldat = compile_dat('4fb9c88f', 'Curtis-Jones', 'Curtis_Jones', checkgames = True)\n",
    "if isinstance(curtis_finaldat, pd.DataFrame):\n",
    "    curtis_finaldat.to_csv(os.path.join(nest_folder, \"curtis_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endo_finaldat = compile_dat('c149016b', 'Wataru-Endo', 'Wataru_Endo', checkgames = True)\n",
    "if isinstance(endo_finaldat, pd.DataFrame):\n",
    "    endo_finaldat.to_csv(os.path.join(nest_folder, \"endo_finaldat.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manchester City"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
